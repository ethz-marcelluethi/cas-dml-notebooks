{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying hand written images \n",
    "\n",
    "So far we have only applied machine learning algorithms to tabular data. In this notebook we will classify data that is not structured and hence it is not possible to label the features. As an example we will classify hand written digits in images. Here the features are the pixel values of the images. We will use the MNIST dataset which is a dataset of 28x28 images of hand written digits. The dataset has 60,000 training images and 10,000 test images.\n",
    "\n",
    "Neural networks are a great choice for such tasks, as they automatically find internal representations of the data that are more meaningful than the raw pixel values. \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the usual libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Reshape, Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data \n",
    "\n",
    "MNist is a very popular dataset and is available in many libraries. We will use the one available directly in TensorFlow. The dataset is already split into training and test sets. We create a separate validation set by splitting the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_val_images, train_val_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Split into training / validation\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_val_images, train_val_labels,\n",
    "                                                                      test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the data we loaded. The first important thing to check is the shape of the data. We can see that the training data has 48,000 images of 28x28 pixels. The labels are integers from 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the shape of the training images:\", train_images.shape)\n",
    "print(\"the shape of the training labels:\", train_labels.shape)\n",
    "print(\"labels \", np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are best looked at visually instead of just looking at the pixel values. We write a function to plot the image. The function also directly prints the label of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(i, images, labels):\n",
    "  image = images[i,:,:]\n",
    "  label = labels[i] \n",
    "  plt.imshow(image, cmap=plt.cm.binary)\n",
    "  plt.grid(True)\n",
    "  plt.gca().set_xticks(np.arange(-0.5, image.shape[1], 1))\n",
    "  plt.gca().set_yticks(np.arange(-0.5, image.shape[0], 1))\n",
    "  plt.gca().set_xticklabels([])\n",
    "  plt.gca().set_yticklabels([])\n",
    "\n",
    "  # we use the color-map (cm) binary in order to see the numbers as\n",
    "  # black-on-white and not white-on-black.\n",
    "  plt.title('the image has the label ' + str(label))\n",
    "\n",
    "show_image(9, train_images, train_labels) # TODO: call the function show_image to show the first image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the values of the pixels, we see that they are in the range of 0 to 255. We will scale the values to be between 0 and 1. Controlling the scale of the input data is important for neural networks as it helps the optimization algorithm to converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"range of pixel values: \", train_images.min(), train_images.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale image data:\n",
    "train_images = train_images / 255.0\n",
    "val_images = val_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The neural network \n",
    "\n",
    "Next we build a neural network. We will use a simple neural network with 1 hidden layers. The input layer has 784 neurons, one for each pixel, the hidden layer has 100 neurons and the output layer has 10 neurons. The output layer has 10 neurons because we have 10 classes. The activation function for the hidden layers is ReLU and for the output layer is softmax, as we would like each output neuron to represent the probability of the image belonging to that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = (28, 28)), # Images are 28x28 pixels \n",
    "    tf.keras.layers.Flatten(), # Flatten the images to a 1D vector\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's configure the model for training. We will use the Adam optimizer and the `sparse_categorical_crossentropy` loss function. We will also monitor the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=\"adam\",\n",
    "  loss=\"sparse_categorical_crossentropy\",\n",
    "  metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, \n",
    "                    train_labels, \n",
    "                    epochs=5, \n",
    "                    batch_size=128, \n",
    "                    validation_data=(val_images, val_labels)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the accuracy. We see that the accuracy is around 97% on the training set and 96% on the validation set. This is a good accuracy for a simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train accuracy: \", history.history[\"accuracy\"][-1])\n",
    "print(\"validation accuracy: \", history.history[\"val_accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating and predicting\n",
    "\n",
    "After the network has been trained, we want to examine how well our model can classify new digits that were not seen during training.\n",
    "\n",
    "To do this, we will first look at how we can use our model and what it returns for an image from the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "print(predictions.shape)\n",
    "print('Prediction for first image ',predictions[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which class has the highest probability? We can use the `argmax` function to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predictions.argmax(axis=1)\n",
    "print('Predicted label', predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(0, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Show the prediction of the class of the first 20 images in the test set and compare it with the actual class.\n",
    "- Which is the first image that is not classified correctly?\n",
    "- Plot a confusion matrix for the test set. Which numbers are often confused with each other?\n",
    "- Visualize this image using the `plot_image` function.\n",
    "- Evaluate the model by using the evaluate function of the model. Print the accuracy. \n",
    "- Train the model for more iterations.\n",
    "- Expand the model and add more layers. Do the errors in the test set decrease with more layers?\n",
    "- Change the number of neurons in the layers. What happens when you use more neurons?\n",
    "- Keep the total number of neurons constant and change the number of layers. What happens when you use more layers? Is it better to have more neurons in one layer or more layers with fewer neurons?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
