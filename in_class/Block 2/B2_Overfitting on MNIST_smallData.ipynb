{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ecf719b",
   "metadata": {},
   "source": [
    "# Classifying MNIST Digits - Reloaded\n",
    "In this notebook, we will dive deeper into the problem of classifying the digits of the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a3c2e",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "We start with the usual preparations. These are very similar to what you have already seen in the previous notebook.\n",
    "\n",
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa8d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Reshape, Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.regularizers import L1, L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875cb90-427a-4a81-92a4-e6c7d7ada867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cc70c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e32db67",
   "metadata": {},
   "source": [
    "### Prepare data\n",
    "Next, we prepare the data. As all images have pixel values in the range between 0 and 255, dividing them by 255 will give us an input on the scale between 0 and 1. Also, we use the usual `train_test_split` function to get separate dataset for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data:\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_val_images, train_val_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Scale image data:\n",
    "train_val_images = train_val_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Split into training / validation\n",
    "train_images_all, val_images, train_labels_all, val_labels = train_test_split(train_val_images, train_val_labels,\n",
    "                                                                              test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a010d-7f99-4b37-ac24-a4cfb798a80a",
   "metadata": {},
   "source": [
    "We look at the distribution of labels on the training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ddaf33-3cc3-4ca0-8fc1-74d1b35f15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_label_df = pd.DataFrame(train_val_labels)\n",
    "train_val_label_df.columns = ['label']\n",
    "train_val_label_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce11e168-87f4-458b-ac21-81fb7648510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label_df = pd.DataFrame(val_labels)\n",
    "val_label_df.columns = ['label']\n",
    "val_label_df['label'].value_counts(sort=False, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45f0ea-23b0-48a4-bf76-1d3acb1fe3f3",
   "metadata": {},
   "source": [
    "We see that both dataset have a pretty even distribution of the labels.\n",
    "\n",
    "Next, we choose a random 1000 samples that we will use for training. While this might look artificial here, it helps us to illustrate the problems related to overfitting while keeping the training times reasonably small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65fa3dd-4552-4c63-a5d0-aa630b4a199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly choose a given number of data points for training\n",
    "n_train = 1000\n",
    "\n",
    "n_train_all = train_images_all.shape[0]\n",
    "train_indices = np.random.choice(range(n_train_all), n_train)\n",
    "\n",
    "train_images = train_images_all[train_indices]\n",
    "train_labels = train_labels_all[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6177aa81-eccd-473e-bd6a-837894b1103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one-hot vector\n",
    "train_labels_OH = to_categorical(train_labels)\n",
    "val_labels_OH = to_categorical(val_labels)\n",
    "test_labels_OH = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c9ee8f-3867-4092-ae7e-c521a32325b7",
   "metadata": {},
   "source": [
    "## Defining the Network\n",
    "We start with a definition of the network that is similar to the one in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9cc3c-5c5c-469d-bb39-56ec27e45adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = (28, 28, 1)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(300, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46460265-436f-4c3b-8d94-dd34838da9b9",
   "metadata": {},
   "source": [
    "Now we compile it and use the `summary` method to get an overview of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2fd3c-b7f8-4ee8-8b58-88cabf8e1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dfaf85-82db-4b46-9598-746dda52ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f181b-3da5-4818-93b0-5b6282b5d8df",
   "metadata": {},
   "source": [
    "## Varying the Training Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d532b-92ba-4325-8800-5e979ec6b29e",
   "metadata": {},
   "source": [
    "### Short Training\n",
    "We start with an initial training over 5 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b5982-fdb3-491f-9a72-cc689795e316",
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpochs = 5\n",
    "mnist_classifier.fit(train_images, train_labels_OH, epochs = nEpochs, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841aa8d8-ab9d-4b0c-b949-7cfb64b8af15",
   "metadata": {},
   "source": [
    "We apply the trained model to the validation imates. Note that we will get, for every image, 10 numbers, representing the probability (as estimated by our model) that the given image represents the corresponding number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c07f2-f8bd-476e-90ae-ac8a2531b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_OH_est = mnist_classifier.predict(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863d4bc-1618-416a-8a73-59c1499ebea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_OH_est[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad7434-9791-4c0b-9d72-51906ca6890f",
   "metadata": {},
   "source": [
    "In order to compare with the label where for each image the corresponding label is given, we search the most probable label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3efae-718e-477f-8432-e486fb6ed298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_est = np.argmax(train_labels_OH_est, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943e74d-aac9-4905-9a3a-1e13861c74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_est[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067916f4-a218-47ae-90c2-80555d0851d9",
   "metadata": {},
   "source": [
    "Let's calculate the accuracy of these predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b70ae-c8ac-4a32-902d-2eb9fb572028",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(train_labels, train_labels_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32576ff-6eb1-4adb-827a-6720ae4339d5",
   "metadata": {},
   "source": [
    "We do the same for the test images, and we also check the confusion matrix on the test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a6c41-1092-4a0d-babe-a46d5953e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels_OH_est = mnist_classifier.predict(val_images)\n",
    "val_labels_est = np.argmax(val_labels_OH_est, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ef5bb-4dbf-4624-bf7e-59f63b147f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(val_labels, val_labels_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd1a62-2740-4cda-b847-25f63edb9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_OH_est = mnist_classifier.predict(test_images)\n",
    "test_labels_est = np.argmax(test_labels_OH_est, 1)\n",
    "accuracy_score(test_labels, test_labels_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379b88da-d976-4871-b03d-cc448e881897",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(test_labels, test_labels_est, normalize='true', values_format='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3cd3b1-feb6-4f52-9d83-1dde5c35cc5a",
   "metadata": {},
   "source": [
    "We store the accuracies in a dataframe that we will expand with the performance of other models as we try them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2aea06-60bc-4ce2-9851-723c1ee29be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_df = pd.DataFrame({'Method': 'Short Training', \n",
    "                              'Training': accuracy_score(train_labels, train_labels_est), \n",
    "                              'Validation': accuracy_score(val_labels, val_labels_est), \n",
    "                              'Test': accuracy_score(test_labels, test_labels_est)}, \n",
    "                             index=['Short Training'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb938b4b-6ff3-49ce-a138-8ce51fd4d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647601c6-2291-4b4b-89c8-b080b82242f5",
   "metadata": {},
   "source": [
    "### More Training Epochs\n",
    "Choosing 5 epochs for training was somewhat arbitrary - and looking at the progress of the loss and the accuracy, we see that both were actually still improving. So let's increase the number of epochs!\n",
    "\n",
    "Note that the training will thus take longer. If you don't want to wait for it to finish, you can just set `train_from_scratch` to `False`, and the trained parameters will be used instead. Note that this will only work if you choose the exact same model as we did. Also, if you are running this notebook locally (on your own computer), you have to download the folder `pretrained` (which contains the pretrained weights) and put it into the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4687c57e-f9c0-4ff7-b5da-62fb96b3864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_from_scratch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d96d7c-9445-4940-b8a3-f4d1aa322f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier_longer = tf.keras.models.clone_model(mnist_classifier)\n",
    "mnist_classifier_longer.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6314e74-92dc-495f-8b22-2ea2949e29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nEpochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d08636-b342-4902-9eb2-157599108462",
   "metadata": {},
   "source": [
    "Furthermore, we would like to keep track of the progress of the fitting. While we can obviously look at the output, the `fit` function also returns a *history*, which we will save as `history_longer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc989c16-13e1-4cee-a368-db9d133ec8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths:\n",
    "classi_weights_path_longer = './pretrained/mnist_small_classi_longer.weights.h5'\n",
    "classi_history_path_longer = './pretrained/mnist_small_classifier_longer.history.h5'\n",
    "\n",
    "if train_from_scratch:\n",
    "    history_longer = mnist_classifier_longer.fit(train_images, train_labels_OH,\n",
    "                                                 epochs = nEpochs, verbose = True)\n",
    "    # Save the weights:\n",
    "    mnist_classifier_longer.save_weights(classi_weights_path_longer)\n",
    "\n",
    "    # Save training history:\n",
    "    with open(classi_history_path_longer, 'wb') as f:\n",
    "        pickle.dump(history_longer, f)\n",
    "else:\n",
    "    # load previsously computed weights\n",
    "    mnist_classifier_longer.load_weights(classi_weights_path_longer)\n",
    "\n",
    "    # load history:\n",
    "    with open(classi_history_path_longer, 'rb') as f:\n",
    "        history_longer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ea4ba-7363-4e87-b735-44cfbb1ea9e2",
   "metadata": {},
   "source": [
    "Below we define a function to plot the history (you don't need to understand how this is done):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516aa99b-542e-4cae-b722-1cea40d709b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, logy=False):\n",
    "    \"\"\"\n",
    "    Plot model training history.\n",
    "    Args:\n",
    "    - history: tensorflow history object.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # plt.subplot(2, 1, 1)\n",
    "    plt.subplot(311)\n",
    "    plt.plot(history['loss'], label='Training')\n",
    "    if 'val_loss' in history.keys():\n",
    "        plt.plot(history['val_loss'], label='Validation')\n",
    "    plt.legend()\n",
    "    plt.ylabel('Loss')\n",
    "    if logy:\n",
    "        plt.yscale('log')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(312)\n",
    "    plt.plot(history['accuracy'], label='Training')\n",
    "    if 'val_accuracy' in history.keys():\n",
    "        plt.plot(history['val_accuracy'], label='Validation')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    if logy:\n",
    "        plt.yscale('log')\n",
    "    plt.grid()    \n",
    "\n",
    "    plt.subplot(313)\n",
    "    plt.plot([1-acc for acc in history['accuracy']], label='Training')\n",
    "    if 'val_accuracy' in history.keys():\n",
    "        plt.plot([1-acc for acc in history['val_accuracy']], label='Validation')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error Rate')\n",
    "    if logy:\n",
    "        plt.yscale('log')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c5b44-d791-4ab5-9312-09e93d6b478f",
   "metadata": {},
   "source": [
    "Now, let's plot the history of our long training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824b5d8-161c-4d1d-9d69-00acd39dbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_longer.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a90f63-45a2-496d-b46a-153577341c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_longer.history, logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79757cf4-e33f-4391-9cb0-4ca1644c064e",
   "metadata": {},
   "source": [
    "It looks like the loss on the training data is continuously decreasing, and the model yields perfectly accurate results. Let's double-check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e1d43-e72d-4ab5-9f26-d250d411b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_OH_est_longer = mnist_classifier_longer.predict(train_images)\n",
    "train_labels_est_longer = np.argmax(train_labels_OH_est_longer, 1)\n",
    "accuracy_score(train_labels, train_labels_est_longer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4add7469-734e-451a-9058-08d8b8fbaf75",
   "metadata": {},
   "source": [
    "Wow, 100% accuracy. But you will of course want to double-check on a new data set - let's see how the model is classifying the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2b6f8-15fe-4de3-b5a5-94e15cdb2e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels_OH_est_longer = mnist_classifier_longer.predict(val_images)\n",
    "val_labels_est_longer = np.argmax(val_labels_OH_est_longer, 1)\n",
    "accuracy_score(val_labels, val_labels_est_longer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1207ef4-e9b3-47e4-8c20-d2a808a3d5ee",
   "metadata": {},
   "source": [
    "A textbook example of overfitting!\n",
    "\n",
    "Since this is a common behavior, `tensorflow` provides some tools to handle this. In particular, \n",
    "* the `compile` function takes as argument `metrics` a metric (or a list of metrics) that will be evalated and printed out after every epoch. For example, we can use \n",
    "`mnist_classifier_longer.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")`\n",
    "* the `fit` function takes an argument `validation_data`, e.g., we can use `validation_data = (val_images, val_labels_OH)`. The loss and all metrics will be evaluated on the validation data after every epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1bfcb-17a6-44d7-83e9-a3e7422f65c8",
   "metadata": {},
   "source": [
    "**EXERCISE**\n",
    "\n",
    "Adapt the cells above to include `metrics` and `validation_data`. Re-train the model and plot the history. Describe your observations.\n",
    "\n",
    "**Hint**: In order to train a model from scratch (e.e., after you have added these arguments), you have to compile the model again! Otherwise, the training will continue from the current parameters of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30731749-9b86-4881-a125-3ffd7be456f7",
   "metadata": {},
   "source": [
    "Again, we store the accuracies in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5bb343-6ca9-4344-86c8-81da1c646c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_OH_est_longer = mnist_classifier_longer.predict(train_images)\n",
    "train_labels_est_longer = np.argmax(train_labels_OH_est_longer, 1)\n",
    "\n",
    "val_labels_OH_est_longer = mnist_classifier_longer.predict(val_images)\n",
    "val_labels_est_longer = np.argmax(val_labels_OH_est_longer, 1)\n",
    "\n",
    "test_labels_OH_est_longer = mnist_classifier.predict(test_images)\n",
    "test_labels_est_longer = np.argmax(test_labels_OH_est_longer, 1)\n",
    "\n",
    "accuracies_df = pd.concat([accuracies_df,\n",
    "                       pd.DataFrame({'Method': 'Long Training', \n",
    "                                     'Training': accuracy_score(train_labels, train_labels_est_longer), \n",
    "                                     'Validation': accuracy_score(val_labels, val_labels_est_longer), \n",
    "                                     'Test': accuracy_score(test_labels, test_labels_est_longer)}, \n",
    "                                    index=['Long Training'])\n",
    "                      ], axis=0)\n",
    "accuracies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b57498-4147-4888-a0f0-b3f6d3bf4638",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "As we are looking at the validation performance, we might as well stop the training once the performance does not improve over a given number of epochs. This is exactly what `EarlyStopping` is doing: We look at a quality criterion specified as `monitor`, and stop the training if we have not seen any improvement in the last `patience` many epochs. If `restore_best_weights`, we restore the weights of the best performing model once we have stopped the training (if `restore_best_weights` is `False`, the latest model weights are used - which is usually not recommneded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a009be-5d70-4b57-b802-e1fcab5fccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier_es = tf.keras.models.clone_model(mnist_classifier)\n",
    "mnist_classifier_es.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78db05-7ee5-42e4-a747-6164097e2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths:\n",
    "classi_weights_path_es = './pretrained/mnist_small_classifier_es.weights.h5'\n",
    "classi_history_path_es = './pretrained/mnist_small_classifier_es.history.h5'\n",
    "\n",
    "if train_from_scratch:\n",
    "    history_es = mnist_classifier_es.fit(train_images, train_labels_OH, validation_data = (val_images, val_labels_OH),\n",
    "                                         epochs = nEpochs, verbose = True, \n",
    "                                         callbacks = [ EarlyStopping(monitor='val_accuracy', patience=10,\n",
    "                                                                     verbose=False, restore_best_weights=True)])\n",
    "\n",
    "    # Save the weights:\n",
    "    mnist_classifier_es.save_weights(classi_weights_path_es)\n",
    "\n",
    "    # Save training history:\n",
    "    with open(classi_history_path_es, 'wb') as f:\n",
    "        pickle.dump(history_es, f)\n",
    "else:\n",
    "    # load previsously computed weights\n",
    "    mnist_classifier_es.load_weights(classi_weights_path_es)\n",
    "\n",
    "    # load history:\n",
    "    with open(classi_history_path_es, 'rb') as f:\n",
    "        history_es = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df18426b-388f-4d05-ae52-5e3167e17ed2",
   "metadata": {},
   "source": [
    "We see that `EarlyStopping` has ended the training after 36 epochs. Looking at the earlier performances, we see that the maximal `val_accuracy` was obtained in epoch 26 with a value of 0.9100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cc7f9-a030-4265-b3da-25b3629202d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_es.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3401e44d-3784-4864-9346-d89c2972fb85",
   "metadata": {},
   "source": [
    "Looking at the history of the training with early stopping, we see that the training stopped as soon as the model was going into overfitting - we see that namely the validation loss starts to increase after around 25 epochs. Hence, EarlyStopping has prevented to model from entering a regime where it is overadapting to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2835174-ed99-4fe3-b2b7-31cd34fa305e",
   "metadata": {},
   "source": [
    "### Function for Training and Analysis\n",
    "In the following, we will look at many more models. To simplify this analysis, we define the following function that will do this for any model. The function will use early stopping for for all trainings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d2f333-8f72-4bb5-a14c-674db931c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_analyse_model(model, model_name, train_from_scratch, classi_weights_path, classi_history_path, \n",
    "                        train_images, train_labels_OH, val_images, val_labels_OH, test_images, test_labels,\n",
    "                        nEpochs = 100, nPatience = 10):\n",
    "\n",
    "    # Train model or load pretrained weights:\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    \n",
    "    if train_from_scratch:\n",
    "        print('Training quietly')\n",
    "        history = model.fit(train_images, train_labels_OH, validation_data = (val_images, val_labels_OH),\n",
    "                                          epochs = nEpochs, verbose = False, \n",
    "                                          callbacks = [ EarlyStopping(monitor='val_accuracy', patience=nPatience,\n",
    "                                                                      verbose=False, restore_best_weights=True)])\n",
    "        # Save the weights:\n",
    "        model.save_weights(classi_weights_path)\n",
    "    \n",
    "        # Save training history:\n",
    "        with open(classi_history_path, 'wb') as f:\n",
    "            pickle.dump(history, f)\n",
    "    else:\n",
    "        # load previsously computed weights\n",
    "        model.load_weights(classi_weights_path)\n",
    "    \n",
    "        # load history:\n",
    "        with open(classi_history_path, 'rb') as f:\n",
    "            history = pickle.load(f)\n",
    "\n",
    "    plt.figure(0)\n",
    "    plot_history(history.history)\n",
    "    \n",
    "    # Evaluate accuracy on training data\n",
    "    train_labels_OH_est = model.predict(train_images)\n",
    "    train_labels_est = np.argmax(train_labels_OH_est, 1)\n",
    "    print('\\nAccuracy on training data:', accuracy_score(train_labels, train_labels_est))\n",
    "\n",
    "    # Evaluate accuracy on validation data\n",
    "    val_labels_OH_est = model.predict(val_images)\n",
    "    val_labels_est = np.argmax(val_labels_OH_est, 1)\n",
    "    print('\\nAccuracy on validation data:', accuracy_score(val_labels, val_labels_est))\n",
    "\n",
    "    # Evaluate accuracy on test data\n",
    "    test_labels_OH_est = model.predict(test_images)\n",
    "    test_labels_est = np.argmax(test_labels_OH_est, 1)\n",
    "    print('Accuracy on testdata:', accuracy_score(test_labels, test_labels_est))\n",
    "\n",
    "    # plot confusion matrix\n",
    "    plt.figure(1)\n",
    "    ConfusionMatrixDisplay.from_predictions(test_labels, test_labels_est, normalize='true', values_format='.2f')\n",
    "    plt.title('Confusion matrix on Test data')\n",
    "    plt.show()\n",
    "\n",
    "    # generate dataframe with accuracy on validation and test data\n",
    "    return pd.DataFrame({'Method': model_name, \n",
    "                         'Training': accuracy_score(train_labels, train_labels_est), \n",
    "                         'Validation': accuracy_score(val_labels, val_labels_est), \n",
    "                         'Test': accuracy_score(test_labels, test_labels_est)}, \n",
    "                        index=[model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f127a97-1869-4db3-b7f9-cf4192a65cfc",
   "metadata": {},
   "source": [
    "We apply this function to evaluate the model with early stopping, and add the performance summary to the overall `accuracies_df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f44bf9-91de-4fc5-930b-3b4f6032837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_es =  train_analyse_model(mnist_classifier_es, 'Early Stopping', train_from_scratch, \n",
    "                                       classi_weights_path_es, classi_history_path_es, \n",
    "                                       train_images, train_labels_OH, val_images, val_labels_OH, test_images, test_labels,\n",
    "                                       nEpochs = 100, nPatience = 10)\n",
    "\n",
    "accuracies_df = pd.concat([accuracies_df, accuracies_es], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8209d1-454d-4809-ba3f-7c5a2418255a",
   "metadata": {},
   "source": [
    "## Avoiding Overfitting\n",
    "Early stopping stops the model before it is overadapting. In this section, we are looking at means to keep a model from overfitting at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfba4df1-6668-4964-9c64-b6c44e1bfff0",
   "metadata": {},
   "source": [
    "### Drop-Out\n",
    "Drop-out layers are a common addition to neural networks to prevent them from overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355a5c78-f7b9-4888-a84a-ca6c1a95dead",
   "metadata": {},
   "source": [
    "#### Drop-Out Rate 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ba8743-2c6e-429d-abee-b8a2b528cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier_do50 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = (28, 28, 1)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(300, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc1eb0-bd73-47ee-bcb9-cb8b38ed3823",
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_weights_path_do50 = './pretrained/mnist_small_classifier_do50.weights.h5'\n",
    "classi_history_path_do50 = './pretrained/mnist_small_classifier_do50.history.h5'\n",
    "\n",
    "accuracies_do50 =  train_analyse_model(mnist_classifier_do50, 'Drop Out 50%', train_from_scratch, \n",
    "                                       classi_weights_path_do50, classi_history_path_do50, \n",
    "                                       train_images, train_labels_OH, val_images, val_labels_OH, test_images, test_labels,\n",
    "                                       nEpochs = 100, nPatience = 10)\n",
    "\n",
    "accuracies_df = pd.concat([accuracies_df, accuracies_do50], axis=0)\n",
    "accuracies_do50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630ee45-f207-4cee-9428-d34ec9c415b7",
   "metadata": {},
   "source": [
    "**EXERCISE**: Vary the model definition to a different drop out rate to investigate the effect on the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f05302b-267f-4b22-964c-77282f73e808",
   "metadata": {},
   "source": [
    "### Weight Regularization\n",
    "\n",
    "Weight regularization puts a penalty on the absolute value of the infered weights. This will keep the model from infering unnecessary large weights.\n",
    "\n",
    "#### L1\n",
    "Note that we have imported the regularizers with the line `from tensorflow.keras.regularizers import L1, L2`, so now we can directly use `L1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e60e2e-e7cc-4811-bcee-98163cd781b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier_kr1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = (28, 28, 1)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(300, activation='relu', kernel_regularizer=L1(0.00025)),\n",
    "    tf.keras.layers.Dense(100, activation='relu', kernel_regularizer=L1(0.00025)),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a4ed60-70c6-4b06-bc83-d249a297ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_weights_path_kr1 = './pretrained/mnist_small_classifier_kr1.weights.h5'\n",
    "classi_history_path_kr1 = './pretrained/mnist_small_classifier_kr1.history.h5'\n",
    "\n",
    "accuracies_kr1 =  train_analyse_model(mnist_classifier_kr1, 'Kernel Reg. L1',\n",
    "                                      train_from_scratch, classi_weights_path_kr1, classi_history_path_kr1,\n",
    "                                      train_images, train_labels_OH, val_images, val_labels_OH, test_images, test_labels,\n",
    "                                      nEpochs = 100, nPatience = 10)\n",
    "\n",
    "accuracies_df = pd.concat([accuracies_df, accuracies_kr1], axis=0)\n",
    "accuracies_kr1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb3e65-5620-43d6-aa80-26ade468c57d",
   "metadata": {},
   "source": [
    "**EXERCISE**: \n",
    "* Play around with different regularization parameters (currently 0.00025)\n",
    "* Adapt the model definition above to an `L2` kernel regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0159a8-2189-4ae0-aaae-5f4bc29a06e8",
   "metadata": {},
   "source": [
    "### Activity Regularization\n",
    "\n",
    "Activity regularization puts a penalty on the extent of the activity. In tensorflow it can be implemented via a separate layer `ActivityRegularization`, with takes parameters `l1` and `l2` for the weight of the corresponding penalties.\n",
    "\n",
    "#### L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a391463-5ff9-4b5e-a641-25cfa117b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier_ar1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape = (28, 28, 1)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(300, activation='relu'),\n",
    "    tf.keras.layers.ActivityRegularization(l1=0.00025),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.ActivityRegularization(l1=0.00025),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bbc99f-4907-44e1-b874-a2952d6470a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_weights_path_ar1 = './pretrained/mnist_small_classifier_ar1.weights.h5'\n",
    "classi_history_path_ar1 = './pretrained/mnist_small_classifier_ar1.history.h5'\n",
    "\n",
    "accuracies_ar1 =  train_analyse_model(mnist_classifier_ar1, 'Activity Reg. L1', \n",
    "                                      train_from_scratch, classi_weights_path_ar1, classi_history_path_ar1, \n",
    "                                      train_images, train_labels_OH, val_images, val_labels_OH, test_images, test_labels,\n",
    "                                      nEpochs = 100, nPatience = 10)\n",
    "\n",
    "accuracies_df = pd.concat([accuracies_df, accuracies_ar1], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd12372e-f64c-4cdb-bfca-65d3e93c2cef",
   "metadata": {},
   "source": [
    "**EXERCISE**: \n",
    "* Play around with different regularization parameters (currently 0.00025)\n",
    "* Adapt the model definition above to an `L2` kernel regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eadcde5-1dc0-477e-94bb-303288d6faa5",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "Below we compare the performance of different models. Note that **you can do this comparison even if you did not do all the exercises above** - it will simply work with all the models you have evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35b1995-dd53-4fb5-9660-937b89302c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_df_long = accuracies_df.melt(id_vars = 'Method')\n",
    "accuracies_df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e82c270-1fd8-4f60-897b-07122fddb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_df_long.rename(columns={'variable': 'Dataset', 'value': 'Accuracy' }, inplace=True)\n",
    "accuracies_df_long['Accuracy'] = 100*accuracies_df_long['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb9caf-440b-437d-b7d4-64bdc4b3022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=accuracies_df_long, x='Accuracy', y='Method', hue='Dataset')\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Accuracy [%]')\n",
    "plt.ylabel('Network Type')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec737fd3-7f87-4d95-b27f-3ffb4b8c0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_df_long['Error Rate'] = 100-accuracies_df_long['Accuracy'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534a121-976f-4119-86f9-d6b9856078bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=accuracies_df_long, x='Error Rate', y='Method', hue='Dataset')\n",
    "plt.legend(loc='lower center')\n",
    "plt.xlabel('Error Rate [%]')\n",
    "plt.ylabel('Network Type')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ea6e1-fc4d-47dc-987d-e1952430d1e6",
   "metadata": {},
   "source": [
    "**EXERCISE**: Comment on these results. Which method do you think works best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd7a2c7-c353-4a0e-9db8-60859215f0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
