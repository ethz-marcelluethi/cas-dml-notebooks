{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158b4d7f-71ec-4c93-9fa5-8e28c19d88c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Analyzing Swiss Large Cap Companies\n",
    "In this notebook we investigate data from the largest 100 publicly traded companies in Switzerland. The data is from: https://www.tradingview.com/markets/stocks-switzerland/market-movers-large-cap/. It has been extracted on September 20, 2024 and preprocessed in the separate notebook (named `large_caps_CH_PREP.ipynb`; which we will look at in the last block). The cleaned version of the dataset is available as comma-separated values in the file `large_caps_CH_20_val-09-20.csv`. We will discuss techniques to prepare data for analysis in the last block; for now we just use the cleaned version of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa739a-ec5b-4b04-b5da-b71ffd9db22d",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "Before we can start, we need to import a number of python libraries that we will be using in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f1834-95e0-4491-9daa-ade7cf3612c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e296d-b885-4cf3-ad79-47ed1a83a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, root_mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56437f-bd61-442c-a8a4-d4ab4eeae9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid unnecessary warnings:\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7779a12-5ec1-4c8a-9070-0603ba585aa1",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "Using the function `read_csv` fron the `pandas` library, we can load the content of a file with comma-separated values into Python. It will be stored in the format of a **DataFrame**, which offers some nice functionality. For now, we limit ourselves to shares with a positive earnings per share (EPS) as well as a positive dividend yield:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c185510-9b10-4bdc-826c-ed8e7bc3e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "largeCaps = pd.read_csv( ... )\n",
    "largeCaps = largeCaps.loc[(largeCaps['DivYield_Prct']>0) & (largeCaps['EPS_CHF']>0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270053ff-d407-4580-8e03-5c13ccbf00cb",
   "metadata": {},
   "source": [
    "In a jupyter notebook, data frames can be displayed nicely by just typing in their names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bebdf09-0048-4837-9c0b-6e27adc01e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205dac7-4a10-4a52-b945-e1863fc7569e",
   "metadata": {},
   "source": [
    "Note that if you are working directly on a console, you have to use a `print` statement, such as `print(largeCap_df)`, but the output is not as nice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fc0d77-81f3-4492-9808-6a6aed44e9dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(largeCaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60c58d-1633-4695-9b17-95dbc77ad2be",
   "metadata": {},
   "source": [
    "## An Overview over the Data\n",
    "To get an overview of the data, all `pandas` DataFrames have two generic methods: \n",
    "\n",
    "* `info()` displays information about the size of the data frame (number of rows and columns), as well as the names, types and available non-empty values for each attribute (or column)\n",
    "* `describe()` gives an overview (in the form of a number of summary statistics) of the numeric column. Columns that are not numeric are dropped for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb3e86-a60a-4688-bec6-ec57499ae973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f6080-78aa-444d-8a1e-d7a78e725528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfcda01-87a4-4dad-ade7-283f0cb77dde",
   "metadata": {},
   "source": [
    "Additionally, the function `value_counts()` can be called for each column of a DataFrame. It counts the number of times each value occurs, and lists them in decreasing number of occurence. This makes sinse in particular for non-numeric attributes, e.g., the `Sector` attribute of the large cap companies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a53fed-8a8d-4a19-be2f-bad740020f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d35a5-ed45-4d1f-a24e-d1b54b8a926e",
   "metadata": {},
   "source": [
    "## Visualisations\n",
    "The above analysis gives a summary over the numeric and categorical values. Next, we will show some visualisations, aiming at a better understanding of the data and potential dependencies between various attributes of the shares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889f263-0825-4957-b402-a1b0762a59c6",
   "metadata": {},
   "source": [
    "### Visualising a Single Dimension\n",
    "A standard way to plot one simple dimension is the so-called *boxplot*, which can easily be plotted using the `boxplot` function from `matplotlib.pyplot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02ed677-b64d-4e27-9bad-b9701de1b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(largeCaps['SharePrice_CHF'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b090029-e15a-4edb-a76e-041dba8fe2ec",
   "metadata": {},
   "source": [
    "We already see that one share has a way higher price than all the others. As the plot is automatically scaled such that all shares fit, we see very little of the other shares. Therefore, we limit ourselves to shares with a price below 20'000 CHF, and plot them again.\n",
    "\n",
    "What we do here is so-called *logical indexing*, i.e., we look at all the rows for which the indicated condition (in our example: `largeCaps['SharePrice_CHF']` is below `20_000`), and we store these into a new variable, called `largeCaps_b20k`. Note that in python, we can use the underscore `_` to make numbers more readable; it has no impact in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2f095-9e6f-4e74-b52b-2dc8355c58c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "largeCaps_b20k = largeCaps.loc[largeCaps['SharePrice_CHF']<20_000, ]\n",
    "plt.boxplot(largeCaps_b20k['SharePrice_CHF'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4c8bd8-41dd-4aef-a3b7-13d5c08724e8",
   "metadata": {},
   "source": [
    "Again, we have one share which has a much higher price than all the others. We limit ourselves further and look only at companies with share price below 5000 CHF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898324d6-21fc-4a57-9aad-bcefd7c433e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# largeCaps_b5k = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9224dda-7999-4454-ad1e-ba1d8d187c34",
   "metadata": {},
   "source": [
    "Now the boxplot gives a better overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38702b-17f4-4d37-a2f8-4768d3a91550",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(largeCaps_b5k['SharePrice_CHF'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63aef18-3701-4d0c-a525-ebb1a2cb77ea",
   "metadata": {},
   "source": [
    "A further common plot type is the so-called histogram. For this, the values (usually on the x-axis) are placed into bins, and then the number of items (or rows - companies, in our case), per bin is counted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e182c-54cd-44d2-ad69-73e8691b1c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data=largeCaps_b5k, x=\"SharePrice_CHF\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9af1c1-9570-4790-b271-b7695551d3cb",
   "metadata": {},
   "source": [
    "Looking under the hood, we see that the function has created a specific data structure, which contains the bin limits (as second element) and the number of items per bin (as first element):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23120742-abbd-41ef-ae3d-fc82ebc2c09b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(data=largeCaps_b5k, x=\"SharePrice_CHF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb1fbd-262b-4eef-90aa-2ebbae7ea1c1",
   "metadata": {},
   "source": [
    "We can also increase the number of bins (or explicitly specify the bin limits) - see the documentation for details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b5947-547e-4370-85ad-0d7d9126b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data=largeCaps_b5k, x=\"SharePrice_CHF\", bins=30)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c745d-53c5-4038-aed0-911f3a261e32",
   "metadata": {},
   "source": [
    "A further possibility (mainly helpful if there are many points, or if you want to compare different groups) are so-called *density plots*. In `seaborn`, we can get them using the function `kdeplot` (where `kde` *stands for kernel density estimation*, which you can roughtly think of a smoothed version of a histogram). A limitation of this type of plot is that it might get too smooth.\n",
    "\n",
    "`seaborn` builds up on top of `matplotlib` and allows us to provide a data frame and then indicate which columns should be used for which axis (and for other plot attributes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bc6388-2f0d-4117-a7fb-948f3fa4ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=largeCaps_b5k, x=\"SharePrice_CHF\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa0fdf5-1152-4e51-a1bb-85e3ea051ea6",
   "metadata": {},
   "source": [
    "This image already shows a potential issue with the smoothed density plots: A negative share price does not make sense, but we see that the smoothing leads to a positive density for negative share prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12474e74-3a02-4ef6-94dc-8f7a5f65d39f",
   "metadata": {},
   "source": [
    "### Visualising Two Dimensions\n",
    "To add some more details, we can visualize more than one attribute in the same plot. For example, we can plot a box plot of the share price *per industry sector*. To do so, we will use `boxplot` from the library `seaborn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4edc832-d463-45a9-b520-a26fd6e180f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=largeCaps_b5k, x=\"SharePrice_CHF\", y=\"Sector\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba66a4-7567-403e-9ed9-005da8ad2c6c",
   "metadata": {},
   "source": [
    "Another very common plot type to visualize two dimensions are the so-called *scatter plots*, which we will use often also in this class. A coordinate system is built up from the two attributes, and each data point (in our case: each share) is plotted at the respective position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc35d0-9e39-4f4d-8a05-65bde8b4db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=largeCaps_b5k['EPS_CHF'], y=largeCaps_b5k['SharePrice_CHF']);\n",
    "plt.xlabel('Earnings per Share [CHF]')\n",
    "plt.ylabel('Share Price [CHF]')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da66de-56a1-445c-9292-1c31094750d9",
   "metadata": {},
   "source": [
    "### Visualising more than Two Dimensions\n",
    "Visualising more than two dimensions is tricky. An extension of the scatterplot into 3D is of course possible, but often hard to actually read.\n",
    "\n",
    "An alternative is the use of color (or the plot symbol) to encode additional information. For example, we can enrich the above scatterplot of *earnings per share* vs *share price* with the sector encoded as color. Again, we use the `seaborn` library, which offers a simple interface to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5458cc-cb2f-46dc-a621-2dd556953923",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=largeCaps_b5k, x='EPS_CHF', y='SharePrice_CHF', hue='Sector')\n",
    "plt.xlabel('Earnings per Share [CHF]')\n",
    "plt.ylabel('Share Price [CHF]')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39614d5a-0fc5-49de-9762-5bc9e9c05f6e",
   "metadata": {},
   "source": [
    "This looks colorful, but is hard to read due to the many sectors. To illustrate this plot with a more helpful example, we limit ourselves to the three sectors with the most companies (see above). We again store these companies in a new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f27f8f-bfd5-4054-b81e-a9b524843c86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "largeCaps_b5k_largeSectors = largeCaps_b5k.loc[largeCaps_b5k['Sector'].isin([ 'Finance', 'Producer manufacturing', 'Health technology' ])]\n",
    "largeCaps_b5k_largeSectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf78996c-374b-4278-9be6-3a86db558af6",
   "metadata": {},
   "source": [
    "Now we do the same plot again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc7ac1-34cf-4603-b4ac-5775a675c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=largeCaps_b5k_largeSectors, x='EPS_CHF', y='SharePrice_CHF', hue='Sector')\n",
    "plt.xlabel('Share Price [CHF]')\n",
    "plt.ylabel('Earnings per Share [CHF]')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7baa10-4de0-44d0-ad0b-7890a03ecb10",
   "metadata": {},
   "source": [
    "Another way to show several dimensions is to create pairwise histograms for every combination of two dimensions. This is done by the `pairwise` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d9d845-8a84-44ac-a667-00f7670c573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(largeCaps_b5k_largeSectors[['MarketCap_BCHF', 'SharePrice_CHF', 'Volume_Shares', 'EPS_CHF', 'DivYield_Prct', 'Sector']], hue='Sector')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fec13e-cc65-4636-97fb-e0b439053bd9",
   "metadata": {},
   "source": [
    "With too many dimensions, however, also this plot becomes very hard to read - and takes time to render. You can try it out below if you don't mind to wait a few moments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78153019-18f7-4a4a-877b-1500be9546d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(largeCaps_b5k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c956b8-bea7-49c3-8879-5c81d2e7154a",
   "metadata": {},
   "source": [
    "## Visualising Correlation\n",
    "Korrelation is a prime statistical measure for the linear dependency between two variables. For any two variables, it lies in the range -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf782a6-d5bf-49c3-9369-a59585f17624",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "heatmap = sns.heatmap(largeCaps_b5k.select_dtypes(include=np.number).corr(), vmin=-1, vmax=1, annot=True, cmap=\"coolwarm_r\")\n",
    "heatmap.set_title('Correlation Heatmap');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a610fe6-b51a-4405-92bf-4b6778ae4fff",
   "metadata": {},
   "source": [
    "If we are interested in the share price `SharePrice_CHF`, the correlation matrix shows us that the earnings per share `EPS_CHF`, the Dividend Yield `DivYield_Prct`, and the Volume of the Shares traded on a given day `Volume_Shares` show the largest absolute correlation. Therefore, let's investigate this in more detail. To do so, we will make some scatter plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab42919-17a5-4354-88fb-6c8a6080e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=largeCaps_b5k['EPS_CHF'], y=largeCaps_b5k['SharePrice_CHF']);\n",
    "plt.xlabel('Earnings per Share [CHF]')\n",
    "plt.ylabel('Share Price [CHF]')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff5e7e0-2068-4095-b291-05a8b2947951",
   "metadata": {},
   "source": [
    "**EXERCISE**: Continue similarly to find out about other dependencies. If you need inspiration, look at the correlation matrix and identify some attributes that might have an influence of the share price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161afa0-1aca-4288-87cd-ea77df2baad1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Formalizing and Evaluating a Linear Dependency Hypothesis\n",
    "The scatterplot above (and the correlation heatmap) might give rise to the hypothesis that the higher the earnings per share, the higher the share price is. We now formalize the assumption as a linear model, using the `scikit-learn` class `LinearRegression`.\n",
    "\n",
    "First, we define which columns of our dataframe we want to use as `X` and `y` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d328d-f1a4-46d8-b8d0-d7e9cef90777",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = largeCaps_b5k[['EPS_CHF']]\n",
    "y = largeCaps_b5k[['SharePrice_CHF']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad636c6a-ae85-4168-8b58-19ad00a6917a",
   "metadata": {},
   "source": [
    "Next, we get a linear model (from `sklearn.linear_model`) and adapt it to the selected data. This processs is called **fitting** or **training**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924de584-54f8-4216-81cb-dadc6dbac09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_sp_vs_eps = LinearRegression()\n",
    "linreg_sp_vs_eps.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fcd983-840e-4c54-9a33-3335b90a7f16",
   "metadata": {},
   "source": [
    "After calling `fit(...)`, the model is now adapted to our data. We can access the parameters (coefficient and intercept) that have been learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea38a97b-1b49-4a3e-918e-63b807b78e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient: ')\n",
    "print(linreg_sp_vs_eps.coef_)\n",
    "print('Intercept:')\n",
    "print(linreg_sp_vs_eps.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6775e84f-23c4-4907-bea1-64b8c296647d",
   "metadata": {},
   "source": [
    "The `seaborn` library offers the function `lmplot` to plot the data together with the linear model, including the confidence region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2bf44-617a-4dd3-95b8-6f8f6bdab327",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=largeCaps_b5k,\n",
    "           x='EPS_CHF', y='SharePrice_CHF', height=4.8, aspect=4/3)\n",
    "plt.xlabel('Earnings per Share [CHF]')\n",
    "plt.ylabel('Share Price [CHF]')\n",
    "plt.title('Earnings per Share vs. Share Price for Swiss Large Caps\\nwith Linear Trend')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db11d1-819a-4649-8e94-aabe1a2106d5",
   "metadata": {},
   "source": [
    "`scikit-learn` also implements a series of quality metrics as ready-made functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a785c4-36aa-4efd-919a-00594deef9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linreg_sp_vs_eps.predict(X)\n",
    "print('r2-Score: ' + str(r2_score(y, y_pred)))\n",
    "print('MSE: ' + str(mean_squared_error(y, y_pred)))\n",
    "print('RMSE: ' + str(root_mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c843c38-937a-49f1-ac0a-473ff3479523",
   "metadata": {},
   "source": [
    "As we will be applying and evaluating several models, we pack this into a function. Besides the printing, the function will also create a new data frame containing the same quality metrics as columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd6e8f5-b72f-4164-8a1b-74b523674d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_eval_model(model, data, y_true, model_name=''):\n",
    "    y_pred = model.predict(data)\n",
    "    print('r2-Score: ' + str(r2_score(y_true, y_pred)))\n",
    "    print('MSE: ' + str(mean_squared_error(y_true, y_pred)))\n",
    "    print('RMSE: ' + str(root_mean_squared_error(y_true, y_pred)))\n",
    "    if len(model_name)>0:\n",
    "        df = pd.DataFrame({'model_name': model_name,\n",
    "                           'r2_score': r2_score(y_true, y_pred),\n",
    "                           'MSE': mean_squared_error(y_true, y_pred),\n",
    "                           'RMS': root_mean_squared_error(y_true, y_pred)},\n",
    "                          index=[model_name])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50c027-3a08-4353-847e-d25ca046d3da",
   "metadata": {},
   "source": [
    "Let us try this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d91187-03b5-44c3-8f0a-8b09114afe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf_sp_vs_eps = apply_eval_model(linreg_sp_vs_eps, X, y, 'EPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb66487c-989c-4ce1-927a-43b38d93337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf_sp_vs_eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d722d1-c957-4d6c-9f04-93f75c5542c4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Evaluation on New Data\n",
    "In order to find out how the shares were developing, we have collected the same data one week later, i.e., on September 27. It is stored in the same format. As above, we limit ourselves to shares with a positive earnings per share (EPS) as well as a positive dividend yield. We will mark all variables related to the later data set by ´_val´ to indicate this is based on the later data we use to validate our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1858d-82f7-4775-ac85-b114dba7e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# largeCaps_val = ...\n",
    "# largeCaps_val_b5k = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39685782-b327-4cf8-9961-bd675c68fefb",
   "metadata": {},
   "source": [
    "Now, using the `apply_eval_model` function we have defined above, we can easily evaluate our model on the new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b723f-b02f-4130-b612-a96a5635ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf_val_sp_vs_eps = apply_eval_model(linreg_sp_vs_eps, largeCaps_val_b5k[['EPS_CHF']],\n",
    "                                          largeCaps_val_b5k[['SharePrice_CHF']], 'EPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c9001-6e81-4877-afc0-878d223a920a",
   "metadata": {},
   "source": [
    "**EXERCISE**: Define and evaluate a few other models. Use the above example as guidance.\n",
    "\n",
    "We recommend you store the data frames containing the model performance in a somewhat descriptive variable name, as we did for `model_perf_val_sp_vs_eps`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d970f905-b300-49c7-97ed-2c8fce580c52",
   "metadata": {},
   "source": [
    "### Comparing the Performance of Several Models\n",
    "We combine the individual performance evaluations into a joint dataframe which we will use afterwards to visualize the performance of the different models on both training and test data. \n",
    "\n",
    "**EXERCISE**: You have to adapt and/or add the names of the individual results, depending on which models you have trained and under which variables you have stored the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ff525",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_perf_all = pd.concat([model_perf_sp_vs_eps, ..., ...])\n",
    "# model_perf_all['date'] = '2024-09-20'\n",
    "\n",
    "# model_perf_val_all = pd.concat([model_perf_val_sp_vs_eps, ..., ...])\n",
    "# model_perf_val_all['date'] = '2024-09-27'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77153f8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now we can get the results of all models considered so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce1f38-f406-4c8c-96e0-9bb652c546b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf_both_sets = pd.concat([model_perf_all, model_perf_val_all])\n",
    "model_perf_both_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51375612",
   "metadata": {},
   "source": [
    "We will do a plot to illustrate the R2-Score and the root mean squared error of the considered models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d813ffcf-bcba-40f0-b22d-4258ed59c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=model_perf_both_sets, x='model_name', y='r2_score', hue = 'date')\n",
    "plt.title('Comparison of Simple Linear Regression Models for Share Price\\nPerformance on 2 different dates')\n",
    "plt.xlabel('Predictor / Independent Variable')\n",
    "plt.ylabel('$R^2$-Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7118b-c2ce-46f9-b3dc-e28baaf05013",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=model_perf_both_sets, x='model_name', y='RMS', hue = 'date')\n",
    "plt.title('Comparison of Simple Linear Regression Models for Share Price\\nPerformance on 2 different dates')\n",
    "plt.xlabel('Predictor / Independent Variable')\n",
    "plt.ylabel('Root Mean Squared Error (RMS)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69356b26-30eb-4dc6-ba38-06634e8fdc73",
   "metadata": {},
   "source": [
    "## Using Several Predictors: Multiple Linear Regression\n",
    "We might well assume that the share price of a company depends not only on one attribute, but on several ones. We can easily expand the linear regression model to a multiple linear model which uses several attributes to predict the share price. All we need to do is to select several columns - the `LinearRegression` model will then determine the right number of parameters for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c64c1-5075-4f8f-a7b7-a5da34f1a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_sp_vs_3 = LinearRegression()\n",
    "linreg_sp_vs_3.fit(largeCaps_val_b5k[['EPS_CHF', 'Volume_Shares', 'DivYield_Prct']], largeCaps_val_b5k['SharePrice_CHF'])\n",
    "\n",
    "model_perf_sp_vs_3 = apply_eval_model(linreg_sp_vs_3, \n",
    "                                      largeCaps_b5k[['EPS_CHF', 'Volume_Shares', 'DivYield_Prct']],\n",
    "                                      largeCaps_b5k['SharePrice_CHF'], \n",
    "                                      'EPS, Vol, DY')\n",
    "\n",
    "model_perf_val_sp_vs_3 = apply_eval_model(linreg_sp_vs_3, \n",
    "                                          largeCaps_val_b5k[['EPS_CHF', 'Volume_Shares', 'DivYield_Prct']],\n",
    "                                          largeCaps_val_b5k['SharePrice_CHF'], \n",
    "                                          'EPS, Vol, DY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5d1bfc-abfb-482f-9720-0e36f8b3612e",
   "metadata": {},
   "source": [
    "Below we add the new model to the model performance dataframe and render the same plots again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23544fb-30d3-4dbc-ad70-f8e202802d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf_sp_vs_3['date'] = '2024-09-20'\n",
    "model_perf_val_sp_vs_3['date'] = '2024-09-27'\n",
    "\n",
    "model_perf_both_sets = pd.concat([model_perf_both_sets, model_perf_sp_vs_3, model_perf_val_sp_vs_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48b6e5-c1f1-4793-962d-a80d313667cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=model_perf_both_sets, x='model_name', y='r2_score', hue = 'date')\n",
    "plt.title('Comparison of Simple Linear Regression Models for Share Price\\nPerformance on 2 different dates')\n",
    "plt.xlabel('Predictor / Independent Variable')\n",
    "plt.ylabel('$R^2$-Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5211a-0e7f-4ddd-a091-9a132b9e1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=model_perf_both_sets, x='model_name', y='RMS', hue = 'date')\n",
    "plt.title('Comparison of Simple Linear Regression Models for Share Price\\nPerformance on 2 different dates')\n",
    "plt.xlabel('Predictor / Independent Variable')\n",
    "plt.ylabel('Root Mean Squared Error (RMS)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7d271-cdde-4aac-9b00-fa4863c51c63",
   "metadata": {},
   "source": [
    "## Statistical Model Selection\n",
    "To conclude, we want to evaluate how well the different models are suited to explain the data. We therefore train the models again, but this time using the library `statsmodels`, which we have already seen in the notebook on polynomical regression. We handle the considered models in the same order as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82e9927-1dcf-4033-ace2-b6287d8673be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_lin_sp_vs_eps = smf.ols('SharePrice_CHF ~ EPS_CHF', data=largeCaps_b5k)\n",
    "sm_lin_sp_vs_eps = sm_lin_sp_vs_eps.fit()\n",
    "sm_lin_sp_vs_eps.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7c55da-989b-4a05-9266-d8330d96fb29",
   "metadata": {},
   "source": [
    "**Comment**: The Omnibus statistic shows that the residuals are very unlikely to follow a normal distribution. It is therefore not a surprise that the model works worse on a new data set. Also, the log-likelihood is very low (compared to other models below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb0415-576f-44a7-961a-f4721b5e3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_lin_sp_vs_dy = smf.ols('SharePrice_CHF ~ DivYield_Prct', data=largeCaps_b5k)\n",
    "sm_lin_sp_vs_dy = sm_lin_sp_vs_dy.fit()\n",
    "sm_lin_sp_vs_dy.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a68bb5-faf9-45ca-8628-6c070f098694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_lin_sp_vs_vs = smf.ols('SharePrice_CHF ~ Volume_Shares', data=largeCaps_b5k)\n",
    "sm_lin_sp_vs_vs = sm_lin_sp_vs_vs.fit()\n",
    "sm_lin_sp_vs_vs.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3961284b-dbd5-4f00-97ef-da141f514dd1",
   "metadata": {},
   "source": [
    "As a comparison, we also investigate the multiple linear model to predict the share price (in linear scale) based on the earnings per share, the volume, and the dividend yield:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c54a03-2040-4043-b6e0-6868443b4bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_lin_sp_vs_t3 = smf.ols('SharePrice_CHF ~ EPS_CHF + Volume_Shares + DivYield_Prct', data=largeCaps_b5k)\n",
    "sm_lin_sp_vs_t3_fit = sm_lin_sp_vs_t3.fit()\n",
    "sm_lin_sp_vs_t3_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04415d-72da-436b-a43c-079228958af7",
   "metadata": {},
   "source": [
    "**Comment:** This model seems to be a very poor fit to the data (see the omnibus statistic); however it reaches a surprisingly high R-squared value. Also on the linear scale, the volumne of the traded shares does not seem to add significantly to the share price. Leaving out the `Volume_Shares`, we indeed get very similar results for all metrics, parameter estimators and residual statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22532c2a-86b8-4c18-b44d-6a4e1348f01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_lin_sp_vs_t2 = smf.ols('SharePrice_CHF ~ EPS_CHF + DivYield_Prct', data=largeCaps_b5k)\n",
    "sm_lin_sp_vs_t2_fit = sm_lin_sp_vs_t2.fit()\n",
    "sm_lin_sp_vs_t2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b1c456-c794-4d94-a2e1-b16b2e4faa94",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Log-Transformation and Share-Price Prediction\n",
    "In this section we will do the log-transformation of the features (EPS, Volume, and Dividend Yield) and the target variable, and then define a linear regression to predict the log-transformed share price. As a first step, we calculate the logaritms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fbc51-6084-4eb6-990c-dfbd4cd921b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Log-transformation to training data\n",
    "largeCaps_b5k['log_SharePrice_CHF'] = np.log(largeCaps_b5k['SharePrice_CHF'])\n",
    "largeCaps_b5k['log_EPS_CHF'] = np.log(largeCaps_b5k['EPS_CHF'])\n",
    "largeCaps_b5k['log_Volume_Shares'] = np.log(largeCaps_b5k['Volume_Shares'])\n",
    "largeCaps_b5k['log_DivYield_Prct'] = np.log(largeCaps_b5k['DivYield_Prct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47365ed0-8d42-42d0-9b58-eb2414599eb2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**EXERCISE**: Do the log-transformation on the three predictors and the target variable (share price) also for the validation data. Then define and train regression models on the log-transformed features. Evaluate their performance on the later data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b462d80d-e1b0-4e58-b721-d11e774decb3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply Log-transformation to validation data\n",
    "# largeCaps_val_b5k['log_SharePrice_CHF'] ...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39c8b4-293c-4c1d-94f8-7f42d2354856",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## A linear Model to Predict the log Share Price from log EPS\n",
    "# Model definition:\n",
    "# linreg_lsp_vs_leps = ...\n",
    "\n",
    "# Model Fitting:\n",
    "# linreg_lsp_vs_leps.fit( ...)\n",
    "\n",
    "# Evaluation on Training Data:\n",
    "# model_perf_lsp_vs_leps = ...\n",
    "\n",
    "# Evaluation on Test Data:\n",
    "# model_perf_val_lsp_vs_leps = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd1b42-b3b8-4040-9a99-8e3822f0d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and evaluate further models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e8a3e-89b1-4519-8ae0-c914af93f730",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Next, we merge the evaluation results for the different models. We do that separately for the training and the test data.\n",
    "\n",
    "**NOTE**: If you choose a different naming convention, you might have to adapt the code here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf1ef3-c89c-408e-a289-07a14f49fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_perf_all_log = pd.concat([model_perf_lsp_vs_leps, model_perf_lsp_vs_ldy, model_perf_lsp_vs_lvs, model_perf_lsp_vs_l3])\n",
    "model_perf_all_log['date'] = '2024-09-20'\n",
    "\n",
    "model_perf_val_all_log = pd.concat([model_perf_val_lsp_vs_leps, model_perf_val_lsp_vs_ldy, model_perf_val_lsp_vs_lvs, model_perf_val_lsp_vs_l3])\n",
    "model_perf_val_all_log['date'] = '2024-09-27'\n",
    "\n",
    "model_perf_both_sets_linlog = pd.concat([model_perf_both_sets, model_perf_all_log, model_perf_val_all_log])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547a407c-b1f1-4039-ba96-77d361651cd6",
   "metadata": {},
   "source": [
    "Now we can plot the performance bar charts including the models with the logarithm transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4218d8-b93d-456b-96fd-fbef59da726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=model_perf_both_sets_linlog, x='model_name', y='r2_score', hue = 'date')\n",
    "plt.title('Comparison of Simple Linear Regression Models for Share Price\\nPerformance on 2 different dates')\n",
    "plt.xlabel('Predictor / Independent Variable')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('$R^2$-Score')\n",
    "plt.legend(loc=(1.05, 0.5))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65e1ac-5c72-408f-9069-fd5c15097088",
   "metadata": {},
   "source": [
    "**EXERCISE**: How to interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867ebbc2-d6bc-4790-827f-0dd38c58497e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Shrinkage Model for Share Price Prediction\n",
    "In this exercise, you will apply the lasso shrinkage method to identify the attributes most relevant to predict the share price. If you run this notebook in the given order, the logarithm of the 3 most correlated features are included in addition to the linear values.\n",
    "\n",
    "Before we can start with the actual shrinkage, we have to scale the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69446c-4109-4bd6-9ab0-4a46a7fe8a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, lasso_path\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc0330-6ad4-4100-b3f0-eb7479f0ff2c",
   "metadata": {},
   "source": [
    "**Note**: Depending on the hyperparameters and the data, the lasso optimization might not converge. In this case, you would get a convergence warning (something like `ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+10, tolerance: 5.518e+07`, with numbers potentially different). This means that the optimization algorithm did not find a good solution. As mentioned in the warning message, a higher regularization can help here. As we are searching for the best hyperparameter, we can assume that the candidate values for which these messages occurr are not yielding a good results and will therefore be discarded. To avoid cluttering of the output, we switch off the display of convergence warnings with the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55bed9b-86ed-4f4a-827e-8dc9efacc42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a038f-2da1-467d-b245-59127e32ae8d",
   "metadata": {},
   "source": [
    "As the scaling is only possible for numerical attributes, we first drop the three non-numerical attributes and store the results as `largeCaps_b5k_num`. Then we can define, fit and apply the scaler. We do this for both the first and the second data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96477be2-52fd-47c4-98a3-c4d8adc8bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "largeCaps_b5k_num = largeCaps_b5k.drop(['Symbol', 'Name', 'Sector'], axis=1)\n",
    "largeCaps_b5k_num = largeCaps_b5k_num.dropna()\n",
    "predictors = largeCaps_b5k_num.drop(['log_SharePrice_CHF', 'SharePrice_CHF'], axis=1)\n",
    "target = largeCaps_b5k_num['SharePrice_CHF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df764ac-7602-4c42-aaff-263f9bc3c117",
   "metadata": {},
   "source": [
    "Next, we scale the predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e147ac-f069-45bf-9bf4-93e86835f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and adapt scaler\n",
    "share_scaler = StandardScaler()\n",
    "share_scaler = share_scaler.fit(predictors)\n",
    "\n",
    "# apply scaling to predictors\n",
    "predictors_std = share_scaler.transform(predictors)\n",
    "predictors_std = pd.DataFrame(predictors_std, columns = predictors.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e6923-0cda-41e3-9cf5-4d46a89fa1c3",
   "metadata": {},
   "source": [
    "**EXERCISE**: Use shrinkage to identify the best predictors for the share price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac26a88-7bcd-4c47-a5b2-d6663e460d1d",
   "metadata": {},
   "source": [
    "Let us now evaluate the model on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038ba24-dad7-475e-aab0-24267f41aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lasso model based on best value for alpha\n",
    "lasso_model_mse = Lasso(alpha=grid_search_mse.best_params_['alpha'])\n",
    "\n",
    "# train model\n",
    "lasso_model_mse.fit(predictors_std, target)\n",
    "\n",
    "# Evaluation on Training Data:\n",
    "model_perf_lasso = apply_eval_model(lasso_model_mse, predictors_std, target, 'lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e53aac-4ea2-454a-a103-5864b14849f6",
   "metadata": {},
   "source": [
    "Again, we want to evaluate this new model on the later data set to see how well this model works on a new data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7fcc1c-deed-426e-a753-2566fc389456",
   "metadata": {},
   "source": [
    "**EXERCISE:** Apply the new model to the later data set `largeCaps_val_b5k`. In order to get a valid result, you have to apply the exact same pre-processing steps as we did to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a21e98-6acb-4e70-b9df-23ee37a21e26",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# largeCaps_val_b5k_num = ...\n",
    "\n",
    "# predictors_val = ...\n",
    "# target_val = ...\n",
    "\n",
    "# ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18fe101-f392-47cf-b577-bb87fc6cb1df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation on Validation Data:\n",
    "# model_perf_val_lasso = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be9502-6311-4bd8-956e-69faf20b8d46",
   "metadata": {},
   "source": [
    "Again we merge the results for a graphical representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c1a80-84ec-4d50-bc13-4b75bfba8735",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merging the result data frames:\n",
    "model_perf_lasso['date'] = '2024-09-20'\n",
    "model_perf_val_lasso['date'] = '2024-09-27'\n",
    "\n",
    "model_perf_all = pd.concat([model_perf_both_sets_linlog, model_perf_lasso, model_perf_val_lasso])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf375d93-fbd2-4c80-b6d8-1d1eff3c7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=model_perf_all, x='model_name', y='r2_score', hue = 'date')\n",
    "plt.title('Comparison of Simple Linear Regression Models for Share Price\\nPerformance on 2 different dates')\n",
    "plt.xlabel('Predictor / Independent Variable')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('$R^2$-Score')\n",
    "plt.legend(loc=(1.05, 0.5))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250bf541-8d7c-4da6-aa71-f042ee5a8ee4",
   "metadata": {},
   "source": [
    "**EXERCISE:** Among the models listed above, which one do you choose to automatically predict the share price? What steps would be necessary to give a dependable estimate of the model performance on new data (you don't have to program it)? Explain why this step is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386f13b-b95f-44e2-b32d-67a0434cf787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
