{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4lmHb826Gx9I",
      "metadata": {
        "id": "4lmHb826Gx9I"
      },
      "source": [
        "# CAS-DML Course Project 4 - Clustering\n",
        "\n",
        "\n",
        "This project is designed to give you a hands-on experience with clustering techniques. You will investigate the structure of a real-world dataset and apply the different clustering methods from the lecture as well as principal component analysis. \n",
        "Furthermore, you will learn how to assess the robustness of your models and how a suitable visualization of the results can help you to interpret the data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fd539bb-32bc-40d8-a22a-4495addc6bb3",
      "metadata": {
        "id": "4fd539bb-32bc-40d8-a22a-4495addc6bb3",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Preparation - importing libraries and loading the data\n",
        "\n",
        "As in the previous projects, we will use numpy for numerical operations, pandas for data manipulation, and matplotlib for plotting. We will also use the scikit-learn library for clustering and PCA. To visualize the data, we will use another library, namely `geopandas`, which is built on top of matplotlib and pandas and allows us to work with geospatial data. You are not expected to understand the details of the `geopandas` library in this course and we will hide all the details from you. However, if you are interested in this topic, you can find more information [here](https://geopandas.org/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25860aed",
      "metadata": {},
      "source": [
        "***Note:*** Geopandas is already installed on our Jupyterhub. If you are working on your local installation of Jupyterlab, you will need to install it using the following command:\n",
        "\n",
        "`conda install -c conda-forge geopandas`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6250f449",
      "metadata": {},
      "source": [
        "With this out of the way, let's import the libraries. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e12a6a5-c559-44ec-99fa-1db6d9bc2651",
      "metadata": {
        "id": "7e12a6a5-c559-44ec-99fa-1db6d9bc2651"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import geopandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fb56a04",
      "metadata": {},
      "source": [
        "In this notebook, we will use a **cleaned subset of the 2019 World Development Indicators dataset**. This preprocessing has been done by the instructors of the course beforehand. Some countries have been removed due to insufficient data. A corresponding notebook will be made available after the project's deadline for those one's who are interested.  \n",
        "\n",
        "Let's load the data and take a look at the first few rows. The country names are unique identifiers for the data points, hence we can set them as the index of the DataFrame. This allows us to access the data for a specific country more easily. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a8e0d19",
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"./cleaned_data.csv\")\n",
        "data = data.set_index(\"Country Name\")\n",
        "data.head(n = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zOxvsyTrLlAu",
      "metadata": {
        "id": "zOxvsyTrLlAu"
      },
      "source": [
        "As we can see the rows (samples) of this dataset represent different countries. The columns (features) are development indicators as measured throughout the countries. Specifically we have:\n",
        "\n",
        "\n",
        "*   ```child_mortality```: Mortality rate, infant (per 1,000 live births)\n",
        "*   ```exports```: Exports of goods and services (% of GDP)\n",
        "*   ```health```: Current health expenditure (% of GDP)\n",
        "*   ```imports```: Imports of goods and services (% of GDP)\n",
        "*   ```income```: Adjusted net national income per capita (current US\\$)\n",
        "*   ```inflation```: Inflation, GDP deflator (annual %)\n",
        "*   ```life_expectancy```: Life expectancy at birth, total (years)\n",
        "*   ```fertility_rate```: Fertility rate, total (births per woman)\n",
        "*   ```gdp_pc```: GDP per capita (current US\\$)\n",
        "*   ```corruption```: Control of corruption. Captures perceptions of the extent to which public power is exercised for private gain. The higher the value the more perceived corruption (orginial inverted)\n",
        "*   ```acc_clean_cooking```: \tAccess to clean fuels and technologies for cooking (% of population)\n",
        "\n",
        "These features should be self-explanatory. A little background on the inflation metric:\n",
        "Inflation, shown by the yearly change in the GDP deflator, tells us how prices are rising across the entire economy. The GDP deflator compares the current value of all goods and services produced to their value in previous years, adjusting for price changes. Those metrics have been inspired by the paper \n",
        "\n",
        "- [Shahriar Sohan et al. <br/> Optimizing development aid allocation: A data-driven approach using unsupervised\n",
        "machine learning and multidimensional indices ](https://wjarr.com/sites/default/files/WJARR-2023-1904.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fda1cdb",
      "metadata": {},
      "source": [
        "As you can easily see, all the features are numeric. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63323e2e-05aa-4ecd-a91a-7b66a8e84106",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63323e2e-05aa-4ecd-a91a-7b66a8e84106",
        "outputId": "8218ea2e-59b0-4e67-d65f-8babff4cf945"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab4b05d3",
      "metadata": {},
      "source": [
        "We will remove `child_mortality` from the dataset. We will use this feature later to evaluate the clustering results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5b487dca",
      "metadata": {},
      "outputs": [],
      "source": [
        "child_mortality = data[\"child_mortality\"]\n",
        "data.drop(\"child_mortality\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d77149b7",
      "metadata": {},
      "source": [
        "Later on we want to color the countries on a map according to their cluster assignment. For this purpose, we will use the `world` dataset from the geopandas library. The following function will take care of all the details of the visualization. You don't need to understand it, just run the cell to make it available for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c9ede772",
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib.colors import to_hex\n",
        "from matplotlib.patches import Patch\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def plot_clusters_on_map(data, labels):\n",
        "    unique_labels = np.unique(labels)\n",
        "    country_categories = []\n",
        "    n_labels = len(np.unique(labels))\n",
        "    for i in range(0, n_labels):\n",
        "      country_categories.append(data.loc[labels == i].index.values.tolist())\n",
        "\n",
        "    url = \"https://nibr1609.github.io/files/world2.geojson\"\n",
        "    map = geopandas.read_file(url)\n",
        "\n",
        "    cmap = plt.cm.get_cmap('tab20', n_labels)  # 'tab20' has 20 distinct colors\n",
        "    category_colors = [to_hex(cmap(i)) for i in range(n_labels)]\n",
        "\n",
        "    # Create a color array to hold the colors for all countries\n",
        "    color_array = ['white'] * len(map)  # Default color for countries not in any category\n",
        "    for i, category in enumerate(country_categories):\n",
        "        # Identify countries in the current category by checking if any country name is in the longer name\n",
        "        highlight = map['NAME'].apply(lambda x: any(x in country for country in category))\n",
        "\n",
        "        # Assign the corresponding color to these countries\n",
        "        color_array = np.where(highlight, category_colors[i], color_array)\n",
        "\n",
        "    # Plot the world map\n",
        "    fig, ax = plt.subplots(figsize=(15, 10))\n",
        "    map.plot(ax=ax, color=color_array, edgecolor='black')\n",
        "    legend_patches = [Patch(color=category_colors[i], label=f\"Category {unique_labels[i]}\") for i in range(n_labels)] + [Patch(color='white', label=\"No Data\")]\n",
        "    plt.title(\"Highlighted Countries on World Map\")\n",
        "    plt.legend(handles=legend_patches, loc='upper left', title=\"Labels\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd12791b-5cda-46f7-9dbd-e59e52108c38",
      "metadata": {
        "id": "bd12791b-5cda-46f7-9dbd-e59e52108c38",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## Explorative Data Analysis\n",
        "\n",
        "Before we start with the clustering, it is always a good idea to take a look at the data. \n",
        "\n",
        "#### Exercise:\n",
        "Please provide some visualization for the features in the dataset. You can use histograms or boxplots to show the distribution of the values for the individual features. You can also use scatter plots to show the relationship between two features. \n",
        "Note down your observations.\n",
        "\n",
        "Think about the individual features and which you would use if the goal of clustering is to find clusters related to heath and which you would use if the goal is to find clusters related to governance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "83e87aa4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "728feedc",
      "metadata": {},
      "source": [
        "YOUR NOTES"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddbbd40f",
      "metadata": {},
      "source": [
        "Did you notice that the features have different scales? As we will illustrate later, this can have a significant impact on the clustering results. Therefore, we will standardize the data before applying the clustering algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5fcbd791",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "data_scaled = StandardScaler().fit_transform(data)\n",
        "data_scaled = pd.DataFrame(data_scaled, columns=data.columns, index=data.index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AIv9j9549dq4",
      "metadata": {
        "id": "AIv9j9549dq4"
      },
      "source": [
        "# Hierarchical Clustering - An Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "urDxsdDK9i-R",
      "metadata": {
        "id": "urDxsdDK9i-R"
      },
      "source": [
        "As mentioned above, the features selected were selected to investigate regions of the world that are most in need of development aid.\n",
        "We start taking all these features and just explore what groupings we can find.\n",
        "\n",
        "We start with hierarchical clustering. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_7AxDzde-ENV",
      "metadata": {
        "id": "_7AxDzde-ENV"
      },
      "source": [
        "Let's plot a dendrogram to visualize the hierarchical clustering. As a linkage method we use `ward` which minimizes the variance of the clusters being merged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AXmLZRdp-Lhv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "AXmLZRdp-Lhv",
        "outputId": "91e64619-45d7-4fa2-9a67-d3f697c71be4"
      },
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "Z = linkage(data_scaled, method='ward')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,45))\n",
        "dendrogram(Z, orientation='left', leaf_font_size=8, labels=list(data.index), color_threshold=3)\n",
        "ax.tick_params(axis='y', which='major', labelsize=12)\n",
        "ax.tick_params(axis='x', which='major', labelsize=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lTEgHvqO-2J8",
      "metadata": {
        "id": "lTEgHvqO-2J8"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "- Which countries are close to each other in the dendrogram? Do you see any surprising results?\n",
        "- Play with the color_threshold parameter. How do you need to choose it such that you get 3 clusters? How for 5 clusters?\n",
        "  - Do the clusters make sense to you? Why or why not?\n",
        "- In how many clusters would you divide the countries based on the dendrogram? Why? Note: There is no right or wrong answer and several solutions are possible. But some might be more reasonable than others. Try to justify your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fe47ad5",
      "metadata": {},
      "source": [
        "YOUR NOTES"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64b87f01",
      "metadata": {},
      "source": [
        "Because the dendogram function doesn't really return us the clusters of countries as list but serves as a visualization of which countries are \"close\" to each other, we want to do hierarchical clustering using the ```AgglomerativeClustering``` from scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "1e5a0f9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "agg_clustering = AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
        "labels = agg_clustering.fit_predict(data_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96d951cf",
      "metadata": {},
      "source": [
        "Now that we have labels, we can print the countries in each cluster.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e5bf435",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# print the countries in each cluster\n",
        "for i in range(0, len(np.unique(labels))):\n",
        "        print(data.loc[labels == i].index.values.tolist())\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65a7ceda",
      "metadata": {},
      "source": [
        "Much better than printing the countries in each cluster is to visualize the clusters on a map. We will use the `plot_clusters_on_map` function that we defined earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfaaefa1",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_clusters_on_map(data, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4e6d71e",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "- Use `AgglomerativeClustering`  to cluster the countries into 5 and 10 clusters. Is there still a clear interpretation of the clusters? Is there anything you learned from the clustering that you didn't know before?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a39c7c52",
      "metadata": {},
      "source": [
        "YOUR ANSWER HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "382b5054",
      "metadata": {},
      "source": [
        "## K-Means\n",
        "\n",
        "*After* applying hierarchical clustering, we want to have a look at another clustering algorithm: **k-Means**. In contrast to hierarchical clustering, we have to specify the number of clusters **before** its execution.\n",
        "While we can specify how many clusters we want in hierarchical clustering, the number of clusters doesn't have to be known before algorithm execution. The linkage matrix can be determined without knowledge of k.\n",
        "\n",
        "With K-Means, we have to specify the number of clusters beforehand. This is a disadvantage of K-Means compared to hierarchical clustering. However, K-Means is computationally more efficient and can be used for larger datasets.\n",
        "\n",
        "### Exercise\n",
        "\n",
        "- Use the `KMeans` to cluster the countries. Do you get the same results as with hierarchical clustering?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8f15467",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "model = ...\n",
        "labels = ...\n",
        "\n",
        "# print the countries in each cluster\n",
        "for i in range(0, len(np.unique(labels))):\n",
        "        print(data.loc[labels == i].index.values.tolist())\n",
        "        print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c162443d",
      "metadata": {},
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dd62acf",
      "metadata": {},
      "source": [
        "## Determining the number of clusters\n",
        "\n",
        "Now we want to determine the optimal number of clusters for the K-Means algorithm. We will use the elbow method for this purpose. The elbow method looks at the sum of squared distances of samples to their closest cluster center. This value is plotted against the number of clusters. The point where the curve starts to flatten out is the optimal number of clusters.\n",
        "\n",
        "In addition to the elbow method, we will also use the silhouette score. It complements the elbow method by providing a measure of how well the data is clustered. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d2e680",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "wcss = []\n",
        "ss = []\n",
        "\n",
        "for i in range(2,15):\n",
        "    # Clustering\n",
        "    model = KMeans(n_clusters=i, n_init=20, random_state=0)\n",
        "    clusters = model.fit_predict(data_scaled)\n",
        "\n",
        "    wcss.append(model.inertia_)\n",
        "    ss.append(silhouette_score(data_scaled, clusters))\n",
        "\n",
        "# create two subplots\n",
        "\n",
        "WCSS = pd.DataFrame({'k': range(2, 15), 'WCSS': wcss, 'SS': ss})\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 10))\n",
        "sns.lineplot(WCSS, x='k', y='WCSS', ax = ax1)\n",
        "ax1.set_title(\"Elbow Method\")\n",
        "sns.lineplot(WCSS, x='k', y='SS', ax = ax2)\n",
        "ax2.set_title(\"Silhouette Score\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ecfa368",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "- How many clusters would you choose based on the above plots? Why?\n",
        "- When you choose the optimal number of clusters and look again at the map, is there an interpretation of the clusters that makes sense to you?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "675383d8",
      "metadata": {},
      "source": [
        "YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07003d35",
      "metadata": {},
      "source": [
        "Let's now visualize the clusters on a map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53c9da1a",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_clusters_on_map(data, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5929996",
      "metadata": {},
      "source": [
        "Remember that we removed the `child_mortality` feature from the dataset? Now we want to use this feature to see if our clustering could be an indicator of child mortality. We will plot the child mortality rate for each country and color the countries according to their cluster assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b228629f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot child mortality rate for each cluster\n",
        "child_mortality_df = child_mortality.to_frame()\n",
        "child_mortality_df[\"Cluster\"] = labels\n",
        "\n",
        "\n",
        "sns.boxplot(data=child_mortality_df, x=\"Cluster\", y=\"child_mortality\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "088808e0",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "- What can you say about the child mortality rate in the different clusters? What does this tell you about your clustering results?\n",
        "- If you wanted to know more about how child mortality is related to the features in the dataset, which method could you use?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a339577a",
      "metadata": {},
      "source": [
        "YOUR NOTES HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85b5b176",
      "metadata": {},
      "source": [
        "#### Assessing the robustness of the clustering\n",
        "\n",
        "We want to assess the robustness of the clustering results as we did in the clustering notebook that we covered in the class. We create a pair of bootstrapped datasets, use them for training a k-means model and compare the cluster assignments that result on the original dataset. If the cluster assignments are similar, the clustering is considered robust."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0fd1142",
      "metadata": {},
      "outputs": [],
      "source": [
        "# produce bootstrap samples for the silhouette score\n",
        "from sklearn.metrics import jaccard_score, adjusted_rand_score\n",
        "\n",
        "ari_scores = []\n",
        "for i in range(100):\n",
        "\n",
        "    bootstrap_sample1 = data_scaled.sample(replace=True, n=len(data_scaled), random_state=i)\n",
        "    km1 = KMeans(n_clusters=5, n_init=40)\n",
        "    km1.fit(bootstrap_sample1)\n",
        "\n",
        "    bootstrap_sample2 = data_scaled.sample(replace=True, n=len(data_scaled), random_state=i)\n",
        "    km2 = KMeans(n_clusters=5, n_init=40)\n",
        "    km2.fit(bootstrap_sample2)\n",
        "    \n",
        "    s1 = km1.predict(data_scaled)\n",
        "    s2 = km2.predict(data_scaled)\n",
        "    ari = adjusted_rand_score(s1, s2)\n",
        "   \n",
        "    ari_scores.append(ari)\n",
        "# plot the distribution of ari scores\n",
        "sns.histplot(ari_scores, bins=30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e852f28",
      "metadata": {},
      "source": [
        "#### Exercise\n",
        "\n",
        "- How do you interpret the distribution of the ARI scores? Would you consider the clustering results to be robust?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b58ee301",
      "metadata": {},
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9823a5ea",
      "metadata": {},
      "source": [
        "### Getting more insights\n",
        "\n",
        "One way to understand if a feature is important for the clustering is to do a box-plot of the feature for all the clusters. \n",
        "Let's choose for simplicity only 3 clusters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3a4328a",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = KMeans(n_clusters=3, n_init=40, random_state=0)\n",
        "labels = model.fit_predict(data_scaled)\n",
        "\n",
        "\n",
        "# do a boxplot for the cluster and each feature\n",
        "data_with_clusters = data_scaled.copy() # copy dataframe in order not to add label to original data\n",
        "data_with_clusters[\"Cluster\"] = labels\n",
        "\n",
        "fig, axs = plt.subplots(len(data_scaled.columns), 1, figsize=(10, 30))\n",
        "for i, col in enumerate(data_scaled.columns):\n",
        "    \n",
        "    sns.boxplot(data=data_with_clusters, x=\"Cluster\", y=col, ax=axs[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e7d1707",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "- Can you use the plots to say what influenced each cluster? What are the defining features for each individual clusters?\n",
        "- We see in the graphs that there are some outliers. Why could this be interesting? You may want to look at the countries that are outliers. In the following code cell you see an example of how to get the countries that are outliers for a specific cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99eb31e",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(data_with_clusters[(data_with_clusters[\"Cluster\"] == 1) & (data_with_clusters[\"imports\"] > 4)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8d99377",
      "metadata": {},
      "source": [
        "YOUR ANSWER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oa_gEjc9_VLK",
      "metadata": {
        "id": "oa_gEjc9_VLK"
      },
      "source": [
        "## Using different features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GiRanBN3Gnqm",
      "metadata": {
        "id": "GiRanBN3Gnqm"
      },
      "source": [
        "Let us now investigate how the choice of features can influence the clustering. \n",
        "If we look at all the features included in our data we see that there are different kind of features (e.g. financial: `imports`, `exports` or `gdp_pc`, governance: `corruption` or health: `acc_clean_cooking`, `health`, `life_expectancy`).  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rT_gHATaIgXl",
      "metadata": {
        "id": "rT_gHATaIgXl"
      },
      "source": [
        "We now want to take a closer look at two different pairs of features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbf560b2-6414-48e2-8e33-67a61caa5a2b",
      "metadata": {
        "id": "fbf560b2-6414-48e2-8e33-67a61caa5a2b",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "#### Feature Set 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x2mRvfTnIs8p",
      "metadata": {
        "id": "x2mRvfTnIs8p"
      },
      "source": [
        "As a first set of features, let's take `acc_clean_cooking` and `life_expectancy`.\n",
        "As a second set of features, we will use `inflation` and `corruption`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "95024354",
      "metadata": {},
      "outputs": [],
      "source": [
        "features_1 = ['acc_clean_cooking', 'life_expectancy']\n",
        "features_2 = ['inflation', 'corruption']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ybtnRjRPI5iA",
      "metadata": {
        "id": "ybtnRjRPI5iA"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "- Produce a scatterplot for each pair of features. Can you see any clusters?\n",
        "- Use the K-Means algorithm to cluster the countries based on these two features. How many clusters would you choose? Why?\n",
        "- Plot the countries with their corresponding clusters on the map. Do the clusters differ from the ones when using all features?\n",
        "\n",
        "*Hint* To restrict a dataframe to only two columns you can use the following code:\n",
        "\n",
        "```python\n",
        "df_subset = df[['feature1', 'feature2']]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "e22f0cbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da78cd0c-7fb5-46cb-92a6-7205daa5635e",
      "metadata": {
        "id": "da78cd0c-7fb5-46cb-92a6-7205daa5635e",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mi5EBc5tUlXc",
      "metadata": {
        "id": "mi5EBc5tUlXc"
      },
      "source": [
        "As we have seen in the previous section, being able to visualize data in two dimension can be very helpful. However, we can't always choose the two features that are most informative for clustering. In such cases, we can use dimensionality reduction techniques to project the data into a lower-dimensional space. We can do this either to visualize the data or to reduce the number of features before applying clustering algorithms.\n",
        "\n",
        "Let's start with the former and use PCA to project the data into a two-dimensional space. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "XzEV-aJK_AEP",
      "metadata": {
        "id": "XzEV-aJK_AEP"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# Normalize\n",
        "num_dim = 2\n",
        "\n",
        "# redo the K-Means clustering\n",
        "model = KMeans(n_clusters=5, n_init=20, random_state=0)\n",
        "labels = model.fit_predict(data_scaled)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=num_dim)\n",
        "transformed_data = pca.fit_transform(data_scaled)\n",
        "\n",
        "# Create a DataFrame with the transformed data and add the labels from the clustering\n",
        "pca_data = pd.DataFrame(transformed_data, columns=[f\"PC{i}\" for i in range(1, num_dim + 1)], index=data.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb2d9c7b",
      "metadata": {},
      "source": [
        "Now that we have a lower-dimensional representation of the data, we can do a scatterplot and show the labels in 2 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "065667b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Plot the data\n",
        "scatter_plot = sns.scatterplot(data=pca_data, x=\"PC1\", y=\"PC2\", hue=labels)\n",
        "\n",
        "# You can uncomment the following code to add the country names to the plot for extreme values\n",
        "for i, row in pca_data.iterrows():\n",
        "    if row['PC1'] > 3 or row['PC2'] > 3 or row['PC1'] < -3 or row['PC2'] < -3:\n",
        "      scatter_plot.text(row['PC1'] + 0.02, row['PC2'], str(row.name), \n",
        "                        fontsize=10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8239562e",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "- Uncomment the code to add some labels to the scatter plot. Are you surprised about the extreme values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6efe404-1955-4fdf-8ec5-a46fe3bbd180",
      "metadata": {
        "id": "e6efe404-1955-4fdf-8ec5-a46fe3bbd180"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE GOES HERE\n",
        "pca = PCA(n_components=num_dim)\n",
        "transformed_data = pca.fit_transform(data_scaled)\n",
        "\n",
        "model = KMeans(n_clusters=5, n_init=20, random_state=0)\n",
        "labels = model.fit_predict(transformed_data)\n",
        "\n",
        "pca_data = pd.DataFrame(transformed_data, columns=[f\"PC{i}\" for i in range(1, num_dim + 1)], index=data.index)\n",
        "\n",
        "scatter_plot = sns.scatterplot(data=pca_data, x=\"PC1\", y=\"PC2\", hue=labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a9fa983",
      "metadata": {},
      "source": [
        "YOUR NOTES HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52b25100",
      "metadata": {},
      "source": [
        "### Optional reading"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3d96e33",
      "metadata": {},
      "source": [
        "Finally, we want to analyze what original features PCA deemed important and what information is represented by the principal components.  \n",
        "Using pca.components_ and a heatmap, we can visualize and explain what features have the biggest influence on the principal components that we obtain by applying PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4963a3da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a DataFrame for PCA loadings\n",
        "loadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i+1}' for i in range(num_dim)], index=data.columns)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(loadings, annot=True, cmap='coolwarm')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fefd4218",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "- Which features have the biggest influence on the first two principal components? \n",
        "- Are all the features that you expected to be important for clustering (see analysis above) represented here?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e9ad807",
      "metadata": {},
      "source": [
        "YOUR_NOTES"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ae6cf71d-fb94-4ea4-8db7-f3e4da32fe15",
        "bd12791b-5cda-46f7-9dbd-e59e52108c38",
        "3bf13321-b695-40c3-bef3-796734e6448d",
        "AIv9j9549dq4",
        "oa_gEjc9_VLK",
        "fbf560b2-6414-48e2-8e33-67a61caa5a2b",
        "72e5e7e9-6d18-47c2-b522-bac816d73437",
        "3a4077da-0aa0-4e2e-88fc-0f9b76ae68cd",
        "a8ce4259-05e3-4490-94e1-6d5fe5036cac",
        "efa7b7b2-e416-4a7a-87c3-0faba968d14a",
        "5c0f7b2b-03f3-4ae8-b462-812255a6ec63",
        "274af124-8c8c-48b4-892c-faf35ad3b87f"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
