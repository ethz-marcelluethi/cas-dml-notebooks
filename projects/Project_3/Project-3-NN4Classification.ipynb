{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: cyan\">\n",
    "This is one of two notebooks about neural networks.\n",
    "One is about neural networks for regression, and the other one about classification. The regression notebook is a bit simpler, and its focus is on the actual neural network and variations of the architecture. The classification notebook is a bit more complex, as you will have to deal with imbalanced data. It also provides more experiments with regularization of neural networks, e.g. using dropout layers.\n",
    "*You don't need to work on both notebooks. Choose the one that best fits your interests.*\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for classification\n",
    "\n",
    "This project helps you get hands-on experiences on neural networks. The project is organized as follows:\n",
    "1. Data preparation\n",
    "2. Define a neural network model\n",
    "3. Role of model architecture\n",
    "4. Overfitting in deep learning\n",
    "    1. Dropout\n",
    "    2. Weight regularization\n",
    "    3. Early stopping\n",
    "5. Other components in deep learning\n",
    "    1. Optimizers\n",
    "    2. Learning rate\n",
    "6. Your own model\n",
    "7. Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations and loading the data\n",
    "\n",
    "We start by importing the necessary libraries. We also set a random seed, for the reproducibility of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next we load the dataset which was used in the classification project.  In this way you can compare neural networks' performance with traditional classifiers.   \n",
    "Remember that the `Net Income Flag` column was constant and hence removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bank_data = pd.read_csv(\"bank_data.csv\") \n",
    "bank_data = bank_data.drop(columns=\"Net Income Flag\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we use a single validation dataset instead of K-fold cross-validation to simplify the pipeline. The strategy is to split the whole dataset into train, validation and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val/test split\n",
    "train_val_df, test_df = train_test_split(bank_data, stratify=bank_data[\"Bankrupt?\"], test_size=0.2, random_state=2024)\n",
    "train_df, val_df = train_test_split(train_val_df, stratify=train_val_df[\"Bankrupt?\"], test_size=0.1, random_state=2024)\n",
    "\n",
    "train_labels = np.array(train_df.pop('Bankrupt?'))\n",
    "val_labels = np.array(val_df.pop('Bankrupt?'))\n",
    "test_labels = np.array(test_df.pop('Bankrupt?'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)\n",
    "\n",
    "print(f'Average class probability in training set:   {train_labels.mean():.4f}')\n",
    "print(f'Average class probability in validation set: {val_labels.mean():.4f}')\n",
    "print(f'Average class probability in test set:       {test_labels.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we normalize the data. We also remove outliers by clipping the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "# Clip the values in range [-5, 5] to remove outliers.\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a neural network model\n",
    "\n",
    "In this section we go through a typical deep learning pipeline, including\n",
    "- Defining the models, determine optimizers and loss\n",
    "- Training\n",
    "- Validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(shape=(train_features.shape[-1],)),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model. This means to combine necessary components together. You must compile it before training.\n",
    "model_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model info\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed in the classification project that the dataset is imbalanced. We used class weights to address this issue. In this project, we will use class weights as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign different weights to class labels, as done in the classification project.\n",
    "neg = len(train_labels[train_labels==0])\n",
    "pos = len(train_labels[train_labels==1])\n",
    "total = neg + pos\n",
    "weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model_1.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    class_weight=class_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a convenience function to plot the training history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  \"\"\"\n",
    "  Plot model training history.\n",
    "  Args:\n",
    "  - history: tensorflow history object.\n",
    "\n",
    "  Returns:\n",
    "  None\n",
    "  \"\"\"\n",
    "  # Plot loss, precision and recall during training\n",
    "  f, axes = plt.subplots(ncols=3, figsize=(24,6))\n",
    "\n",
    "  sns.lineplot(x=history.epoch, y=history.history['loss'], ax=axes[0], label='Train loss')\n",
    "  sns.lineplot(x=history.epoch, y=history.history['val_loss'], ax=axes[0], label='Val loss')\n",
    "  axes[0].set_title('Loss history')\n",
    "  axes[0].set(yscale='log') # Use a log scale on y-axis to show the wide range of values.\n",
    "  axes[0].set(xlabel='Epoch', ylabel='Loss')\n",
    "\n",
    "  sns.lineplot(x=history.epoch, y=history.history['precision'], ax=axes[1], label='Train precision')\n",
    "  sns.lineplot(x=history.epoch, y=history.history['val_precision'], ax=axes[1], label='Val precision')\n",
    "  axes[1].set_title('Precision history')\n",
    "  axes[1].set(xlabel='Epoch', ylabel='Precision')\n",
    "\n",
    "  sns.lineplot(x=history.epoch, y=history.history['recall'], ax=axes[2], label='Train recall')\n",
    "  sns.lineplot(x=history.epoch, y=history.history['val_recall'], ax=axes[2], label='Val recall')\n",
    "  axes[2].set_title('Recall history')\n",
    "  axes[2].set(xlabel='Epoch', ylabel='Recall')\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed that the loss is decreasing as expected and the precision is improving with the number of epochs. The recall is, however, decreasing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "- Can you think of a reason why the recall is decreasing? Hint: What is optimized in the loss?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain more insight about the performance of the model, we compute the same classification metrics that we already used in the classification project. In particular, we will also look at the trade-off between precision and recall by plotting the precision-recall curve.\n",
    "\n",
    "As we will evaluate a lot of models, we define a convenience function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay\n",
    "\n",
    "# The same evaluation will be used multiple times, so we make it a function\n",
    "def evaluate_model(model, model_name, test_features, test_labels):\n",
    "  \"\"\"\n",
    "  Evaluate trained models. Plot ROC curve and PR curve.\n",
    "  Args:\n",
    "  - model: tensorflow model. trained neural network\n",
    "  - model_name: str.\n",
    "  - test_features: np.array.\n",
    "  - test_labels: np.array.\n",
    "\n",
    "  Returns:\n",
    "  - results: dict.\n",
    "  \"\"\"\n",
    "  results = {}\n",
    "  labels_score = model.predict(test_features)\n",
    "  pred_labels = np.where(labels_score > 0.5, 1, 0)\n",
    "\n",
    "  results['accuracy'] = accuracy_score(test_labels, pred_labels)\n",
    "  results['balanced_accuracy'] = balanced_accuracy_score(test_labels, pred_labels)\n",
    "  results['precision'] = precision_score(test_labels, pred_labels)\n",
    "  results['recall'] = recall_score(test_labels, pred_labels)\n",
    "  results['f1'] = f1_score(test_labels, pred_labels)\n",
    "  print(\"Accuracy\", results['accuracy'])\n",
    "  print(\"Balanced Accuracy\", results['balanced_accuracy'])\n",
    "  print(\"Precision\", results['precision'])\n",
    "  print(\"Recall\", results['recall'])\n",
    "  print(\"F1\", results['f1'])\n",
    "\n",
    "  fpr, tpr, thresholds = roc_curve(test_labels, labels_score)\n",
    "  roc_auc = roc_auc_score(test_labels, labels_score)\n",
    "  print('ROC-AUC Score:', roc_auc)\n",
    "  precision, recall, thresholds = precision_recall_curve(test_labels, labels_score)\n",
    "  pr_auc = auc(recall, precision)\n",
    "  print('PR-AUC Score:', pr_auc)\n",
    "\n",
    "  results['roc_auc'] = roc_auc\n",
    "  results['pr_auc'] = pr_auc\n",
    "\n",
    "  f, axes = plt.subplots(ncols=2, figsize=(18,6))\n",
    "  disp = RocCurveDisplay(fpr=fpr, tpr=tpr, estimator_name=model_name)\n",
    "  disp.plot(ax=axes[0])\n",
    "  disp = PrecisionRecallDisplay(precision=precision, recall=recall, estimator_name=model_name)\n",
    "  disp.plot(ax=axes[1])\n",
    "  plt.show()\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also define a convenience function to show all the results. Note, you don't need to understand the code in this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "def display_benchmark(benchmark):\n",
    "  \"\"\"\n",
    "  Display benchmark results in a DataFrame.\n",
    "  Args:\n",
    "  - benchmark: dict.\n",
    " \"\"\"\n",
    "  df =  pd.DataFrame.from_dict(benchmark, orient='index', columns=[\"accuracy\", \"balanced_accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\", \"pr_auc\"])\n",
    "  display(HTML(\"<bf>Summary of all results</bf>\"))\n",
    "  display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For gathering all evaluation results\n",
    "benchmark = {}\n",
    "benchmark['baseline'] = evaluate_model(model_1, \"Model 1\", test_features, test_labels)\n",
    "\n",
    "display_benchmark(benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You've finished a typical pipeline of training a neural network. In the following sections, we will discuss more about model architecture, overfit and underfit, as well as other components in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a larger network.\n",
    "\n",
    "We can now try to obtain a better model by increasing the number of hidden layers and the number of neurons in each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "- Define a wider and deeper network that's composed of 3 layers of 256 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2 = ...\n",
    "\n",
    "# model_2.compile(optimizer='adam',\n",
    "#        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "#        metrics=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "# model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_2 = model_2.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    class_weight=class_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_2)\n",
    "benchmark['wider'] = evaluate_model(model_2, \"Model 2\", test_features, test_labels)\n",
    "\n",
    "display_benchmark(benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Is the model better or worse than the previous?\n",
    "- Look at the training history. What phenomenon do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "In the following we look at different regularization techniques to prevent overfitting.\n",
    "\n",
    "### Dropout\n",
    "\n",
    "The term “dropout” refers to dropping out the nodes (input and hidden layer) in a neural network. All the forward and backwards connections with a dropped node are temporarily removed, thus creating a new network architecture out of the parent network. The nodes are dropped by a dropout probability of $p$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same architecture as model 2, but with dropout to prevent overfitting\n",
    "model_3 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(shape=(train_features.shape[-1],)),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.5), # Add dropout layer\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.5), # Add dropout layer\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_3.compile(optimizer='adam',\n",
    "       loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "       metrics=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight regularization\n",
    "\n",
    "Another common way to mitigate overfitting is to put constraints on the complexity of a network by forcing its weights only to take small values, which makes the distribution of weight values more \"regular\". This is called \"weight regularization\", and it is done by adding to the loss function of the network a cost associated with having large weights. This cost comes in two flavors:\n",
    "\n",
    "- L1 regularization, where the cost added is proportional to the absolute value of the weights coefficients (i.e. to what is called the \"L1 norm\" of the weights).\n",
    "\n",
    "- L2 regularization, where the cost added is proportional to the square of the value of the weights coefficients (i.e. to what is called the squared \"L2 norm\" of the weights). L2 regularization is also called weight decay in the context of neural networks. Don't let the different name confuse you: weight decay is mathematically the exact same as L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same architecture as model 2, but with L2 regularization to prevent overfitting\n",
    "model_4 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(shape=(train_features.shape[-1],)),\n",
    "  tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "  tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_4.compile(optimizer='adam',\n",
    "       loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "       metrics=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "1. Train the two models (`model_3` and `model_4`). Do they avoid overfitting?\n",
    "2. Plot the history of the models and do the evaluations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_3 = ...\n",
    "\n",
    "plot_history(history_3)\n",
    "\n",
    "benchmark[\"dropout\"] = ...\n",
    "display_benchmark(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4 = ...\n",
    "\n",
    "plot_history(history_4)\n",
    "\n",
    "benchmark[\"l2_reg\"] = ...\n",
    "display_benchmark(benchmark)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early stopping\n",
    "\n",
    "Yet another way to prevent overfitting is to stop the training when the performance on the validation set starts to degrade. This is called early stopping.\n",
    "\n",
    "During training, the model is evaluated on the validation dataset after each epoch. If the performance of the model on the validation dataset starts to degrade (e.g. loss begins to increase or accuracy begins to decrease), then the training process is stopped.\n",
    "\n",
    "In contrast to regularization, early stopping is not defined when compiling the model. Instead, it is a callback that is passed to the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stop callback. It continuously monitors the validation loss. If the loss stops decreasing for 10 epochs, the training automatically stops and the best weights are restored.\n",
    "# The callback will be used in the fit method later.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "# Same architecture as model 2, but with L2 regularization to prevent overfitting\n",
    "model_5 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Input(shape=(train_features.shape[-1],)),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_5.compile(optimizer='adam',\n",
    "       loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "       metrics=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "model_5.summary()\n",
    "\n",
    "history_5 = model_5.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[early_stopping]  # <-- Early stopping\n",
    "    )\n",
    "\n",
    "plot_history(history_5)\n",
    "benchmark['early_stopping'] = evaluate_model(model_5, \"Model 5\", test_features, test_labels)\n",
    "display_benchmark(benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other components in deep learning\n",
    "\n",
    "Besides the architecture and the regularization, there are other components that are important in deep learning. In this section, we will discuss the optimizer and the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is the most commonly used optimization algorithm in deep learning. There are many variations of gradient descent. Below is a non-comprehensive list\n",
    "\n",
    "- SGD (`tf.keras.optimizers.SGD()`)\n",
    "- Adagrad (`tf.keras.optimizers.Adagrad()`)\n",
    "- Adadelta (`tf.keras.optimizers.Adadelta()`)\n",
    "- Adam (`tf.keras.optimizers.Adam()`)\n",
    "- AdamW (`tf.keras.optimizers.AdamW()`)\n",
    "\n",
    "You can choose any of them to experiment. The following code (which is not a runnable) shows how you could compile the model with the Adam optimizer\n",
    "\n",
    "```python\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "       loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "       metrics=['accuracy', 'precision', 'recall'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate\n",
    "\n",
    "The learning rate controls how quickly the model is adapted to the problem. Smaller learning rates require more training epochs given the smaller changes made to the weights each update, whereas larger learning rates result in rapid changes and require fewer training epochs.\n",
    "\n",
    "A learning rate that is too large can cause the model to converge too quickly to a suboptimal solution, whereas a learning rate that is too small can cause the process to get stuck.\n",
    "\n",
    "The learning rate is given as an argument when defining the optimizer. For example, to set the learning rate to 0.01, you can use the following code:\n",
    "\n",
    "```python\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your own model\n",
    "\n",
    "In this section you will define your own model, based on everything you learned from previous sections.\n",
    "\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Define a model with suitable architecture and techniques for preventing overfitting.\n",
    "\n",
    "Can you achieve the following performance on the validation set\n",
    "- balanced_accuracy > 0.8\n",
    "- precision > 0.15\n",
    "- recall > 0.8\n",
    "- almost no overfitting\n",
    "\n",
    "Hint:\n",
    "1. Make the network bigger (wider and deeper) and use smaller learning rate (but not as small as 0.0001)\n",
    "2. Combine different methods, such as dropout, early stop and weight regularization to avoid overfitting\n",
    "3. Train longer and use larged batch size\n",
    "4. Use robust optimizers, such as Adam, AdamW\n",
    "\n",
    "You perhaps need many experiments to find the best combination. It is suggested to keep track of parameters you have used. You can create many cells and keep them here.\n",
    "\n",
    "When you finish your experiments, answer the following questions:\n",
    "1. How does the model perform on validation and test set?\n",
    "2. What is the best model you have found?\n",
    "3. How does it compare to the models from project 2? Is it better than XGBoost?\n",
    "\n",
    "To answer the last question, we have compiled the results of the models from project 2. You can find them in the following table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project2_results = pd.read_csv(\"classification_results.csv\", index_col=0)\n",
    "project2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on evaluation results\n",
    "benchmark['model_own'] = evaluate_model(model_own, \"Own model\", test_features, test_labels)\n",
    "display_benchmark(benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "- Compare the results of deep learning models with the results of traditional classifiers, such as KNN, decision trees and XGBoost.\n",
    "- Do deep learning models outperform traditional classifiers in terms of precision, recall and f1-score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
